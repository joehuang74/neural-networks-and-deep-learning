===== Training file list =====
svm_traindata.txt.1a.KDP_0.5_0.5.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_0.5_0.5.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_0.5_0.5.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_0.5_0.5.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_0.5_0.5.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_0.5_0.5.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_0.5_0.5.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_1.5_1.5.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_1.5_1.5.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_1.5_1.5.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_1.5_1.5.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_1.5_1.5.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_1.5_1.5.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_1.5_1.5.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_2.4_2.4.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_2.4_2.4.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_2.4_2.4.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_2.4_2.4.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_2.4_2.4.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_2.4_2.4.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_2.4_2.4.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_3.4_3.4.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_3.4_3.4.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_3.4_3.4.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_3.4_3.4.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_3.4_3.4.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_3.4_3.4.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_3.4_3.4.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_4.3_4.3.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_4.3_4.3.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_4.3_4.3.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_4.3_4.3.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_4.3_4.3.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_4.3_4.3.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_4.3_4.3.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_6.0_6.0.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_6.0_6.0.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_6.0_6.0.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_6.0_6.0.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_6.0_6.0.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_6.0_6.0.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.KDP_6.0_6.0.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_0.5_0.5.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_0.5_0.5.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_0.5_0.5.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_0.5_0.5.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_0.5_0.5.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_0.5_0.5.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_0.5_0.5.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_1.5_1.5.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_1.5_1.5.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_1.5_1.5.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_1.5_1.5.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_1.5_1.5.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_1.5_1.5.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_1.5_1.5.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_2.4_2.4.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_2.4_2.4.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_2.4_2.4.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_2.4_2.4.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_2.4_2.4.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_2.4_2.4.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_2.4_2.4.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_3.4_3.4.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_3.4_3.4.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_3.4_3.4.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_3.4_3.4.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_3.4_3.4.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_3.4_3.4.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_3.4_3.4.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_4.3_4.3.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_4.3_4.3.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_4.3_4.3.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_4.3_4.3.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_4.3_4.3.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_4.3_4.3.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_4.3_4.3.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_6.0_6.0.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_6.0_6.0.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_6.0_6.0.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_6.0_6.0.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_6.0_6.0.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_6.0_6.0.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.ZDR_6.0_6.0.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_0.5_0.5.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_0.5_0.5.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_0.5_0.5.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_0.5_0.5.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_0.5_0.5.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_0.5_0.5.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_0.5_0.5.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_1.5_1.5.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_1.5_1.5.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_1.5_1.5.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_1.5_1.5.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_1.5_1.5.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_1.5_1.5.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_1.5_1.5.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_2.4_2.4.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_2.4_2.4.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_2.4_2.4.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_2.4_2.4.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_2.4_2.4.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_2.4_2.4.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_2.4_2.4.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_3.4_3.4.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_3.4_3.4.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_3.4_3.4.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_3.4_3.4.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_3.4_3.4.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_3.4_3.4.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_3.4_3.4.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_4.3_4.3.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_4.3_4.3.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_4.3_4.3.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_4.3_4.3.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_4.3_4.3.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_4.3_4.3.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_4.3_4.3.sd.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_6.0_6.0.max.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_6.0_6.0.max5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_6.0_6.0.mean.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_6.0_6.0.mid.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_6.0_6.0.min.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_6.0_6.0.min5.HourlyAggr.fuzzy
svm_traindata.txt.1a.Z_6.0_6.0.sd.HourlyAggr.fuzzy
training_data_dir: D:\\svmdata.10minPrecipAsLabel.HourlyAggr.FuzzyLabel\svm_case2.1_merged_all_stat
rainfall_min_value: 0
rainfall_max_value: 100
n_rainfall_indexes(Number of neurons for output-layer): 100
size_hidden_layer(Number of neurons for hidden-layer): 30
kernel type: Sigmoid
epoches: 20
mini_batch_size: 10
training_rate: 2.0

===== svm_traindata.txt.1a.KDP_0.5_0.5.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 11 / 36
Epoch 10: 23 / 36
Epoch 11: 11 / 36
Epoch 12: 24 / 36
Epoch 17: 24 / 36
Epoch 18: 25 / 36
Epoch 19: 11 / 36
Result after 20 epoches: 11 / 36  (30%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 15 / 36
Epoch 10: 24 / 36
Epoch 11: 24 / 36
Epoch 12: 24 / 36
Epoch 17: 24 / 36
Epoch 18: 11 / 36
Epoch 19: 24 / 36
Result after 20 epoches: 24 / 36  (66%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 13 / 36
Epoch 10: 23 / 36
Epoch 11: 11 / 36
Epoch 12: 24 / 36
Epoch 17: 23 / 36
Epoch 18: 12 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 1 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 11 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 24 / 36
Epoch 10: 11 / 36
Epoch 11: 11 / 36
Epoch 12: 16 / 36
Epoch 17: 15 / 36
Epoch 18: 23 / 36
Epoch 19: 24 / 36
Result after 20 epoches: 24 / 36  (66%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 24 / 36
Epoch 10: 24 / 36
Epoch 11: 18 / 36
Epoch 12: 24 / 36
Epoch 17: 16 / 36
Epoch 18: 24 / 36
Epoch 19: 21 / 36
Result after 20 epoches: 21 / 36  (58%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 11 / 36
Epoch 10: 22 / 36
Epoch 11: 11 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 13 / 36
Epoch 19: 21 / 36
Result after 20 epoches: 21 / 36  (58%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 16 / 36
Epoch 19: 11 / 36
Result after 20 epoches: 11 / 36  (30%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 23 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 24 / 36
Epoch 10: 17 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 24 / 36
Epoch 19: 25 / 36
Result after 20 epoches: 25 / 36  (69%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 11 / 36
Epoch 1: 11 / 36
Epoch 2: 11 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 11 / 36
Epoch 18: 24 / 36
Epoch 19: 24 / 36
Result after 20 epoches: 24 / 36  (66%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 26 / 36
Epoch 19: 12 / 36
Result after 20 epoches: 12 / 36  (33%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 11 / 36
Epoch 12: 23 / 36
Epoch 17: 17 / 36
Epoch 18: 23 / 36
Epoch 19: 19 / 36
Result after 20 epoches: 19 / 36  (52%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 19 / 36
Epoch 10: 19 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 11 / 36
Epoch 18: 11 / 36
Epoch 19: 19 / 36
Result after 20 epoches: 19 / 36  (52%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 11 / 36
Epoch 1: 11 / 36
Epoch 2: 11 / 36
Epoch 9: 11 / 36
Epoch 10: 11 / 36
Epoch 11: 11 / 36
Epoch 12: 11 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 24 / 36
Epoch 10: 11 / 36
Epoch 11: 22 / 36
Epoch 12: 23 / 36
Epoch 17: 24 / 36
Epoch 18: 18 / 36
Epoch 19: 21 / 36
Result after 20 epoches: 21 / 36  (58%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 24 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 11 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 11 / 36
Epoch 19: 11 / 36
Result after 20 epoches: 11 / 36  (30%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 21 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 19 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 11 / 36
Epoch 10: 23 / 36
Epoch 11: 11 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 11 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 11 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 24 / 36
Epoch 17: 11 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 11 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 23 / 36
Epoch 18: 11 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 11 / 36
Epoch 1: 11 / 36
Epoch 2: 11 / 36
Epoch 9: 11 / 36
Epoch 10: 11 / 36
Epoch 11: 11 / 36
Epoch 12: 11 / 36
Epoch 17: 11 / 36
Epoch 18: 11 / 36
Epoch 19: 11 / 36
Result after 20 epoches: 11 / 36  (30%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 18 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 11 / 36
Result after 20 epoches: 11 / 36  (30%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 21 / 36
Result after 20 epoches: 21 / 36  (58%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 22 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 22 / 36
Epoch 10: 23 / 36
Epoch 11: 11 / 36
Epoch 12: 23 / 36
Epoch 17: 11 / 36
Epoch 18: 11 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 11 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 23 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 20 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 11 / 36
Result after 20 epoches: 11 / 36  (30%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 11 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 16 / 36
Epoch 18: 11 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 3 / 36
Epoch 1: 1 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 21 / 36
Epoch 18: 23 / 36
Epoch 19: 22 / 36
Result after 20 epoches: 22 / 36  (61%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 17 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 20 / 36
Epoch 12: 24 / 36
Epoch 17: 22 / 36
Epoch 18: 20 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 20 / 36
Epoch 9: 22 / 36
Epoch 10: 18 / 36
Epoch 11: 23 / 36
Epoch 12: 20 / 36
Epoch 17: 23 / 36
Epoch 18: 14 / 36
Epoch 19: 11 / 36
Result after 20 epoches: 11 / 36  (30%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 11 / 36
Epoch 1: 11 / 36
Epoch 2: 11 / 36
Epoch 9: 23 / 36
Epoch 10: 11 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 11 / 36
Epoch 18: 20 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 20 / 36
Epoch 17: 23 / 36
Epoch 18: 17 / 36
Epoch 19: 11 / 36
Result after 20 epoches: 11 / 36  (30%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 12 / 36
Epoch 11: 15 / 36
Epoch 12: 22 / 36
Epoch 17: 11 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 18 / 36
Epoch 11: 24 / 36
Epoch 12: 24 / 36
Epoch 17: 24 / 36
Epoch 18: 25 / 36
Epoch 19: 25 / 36
Result after 20 epoches: 25 / 36  (69%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 25 / 36
Epoch 10: 24 / 36
Epoch 11: 16 / 36
Epoch 12: 20 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 23 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 23 / 36
Epoch 1: 23 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 24 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 13 / 36
Epoch 18: 23 / 36
Epoch 19: 21 / 36
Result after 20 epoches: 21 / 36  (58%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 23 / 36
Epoch 18: 16 / 36
Epoch 19: 20 / 36
Result after 20 epoches: 20 / 36  (55%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 22 / 36
Epoch 10: 23 / 36
Epoch 11: 16 / 36
Epoch 12: 24 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 16 / 36
Result after 20 epoches: 16 / 36  (44%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 25 / 36
Epoch 10: 21 / 36
Epoch 11: 20 / 36
Epoch 12: 11 / 36
Epoch 17: 25 / 36
Epoch 18: 24 / 36
Epoch 19: 24 / 36
Result after 20 epoches: 24 / 36  (66%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 25 / 36
Epoch 18: 11 / 36
Epoch 19: 21 / 36
Result after 20 epoches: 21 / 36  (58%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 20 / 36
Epoch 11: 11 / 36
Epoch 12: 13 / 36
Epoch 17: 23 / 36
Epoch 18: 25 / 36
Epoch 19: 22 / 36
Result after 20 epoches: 22 / 36  (61%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 11 / 36
Epoch 2: 23 / 36
Epoch 9: 23 / 36
Epoch 10: 11 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 23 / 36
Epoch 18: 12 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 24 / 36
Epoch 10: 24 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 24 / 36
Epoch 18: 22 / 36
Epoch 19: 24 / 36
Result after 20 epoches: 24 / 36  (66%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 24 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 23 / 36
Epoch 18: 17 / 36
Epoch 19: 24 / 36
Result after 20 epoches: 24 / 36  (66%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 11 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 25 / 36
Epoch 17: 23 / 36
Epoch 18: 25 / 36
Epoch 19: 25 / 36
Result after 20 epoches: 25 / 36  (69%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 25 / 36
Epoch 18: 11 / 36
Epoch 19: 11 / 36
Result after 20 epoches: 11 / 36  (30%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 11 / 36
Epoch 10: 11 / 36
Epoch 11: 23 / 36
Epoch 12: 23 / 36
Epoch 17: 13 / 36
Epoch 18: 11 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 23 / 36
Epoch 2: 21 / 36
Epoch 9: 23 / 36
Epoch 10: 21 / 36
Epoch 11: 23 / 36
Epoch 12: 11 / 36
Epoch 17: 23 / 36
Epoch 18: 23 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 23 / 36
Epoch 10: 23 / 36
Epoch 11: 23 / 36
Epoch 12: 24 / 36
Epoch 17: 22 / 36
Epoch 18: 25 / 36
Epoch 19: 25 / 36
Result after 20 epoches: 25 / 36  (69%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 25 / 36
Epoch 10: 24 / 36
Epoch 11: 23 / 36
Epoch 12: 24 / 36
Epoch 17: 24 / 36
Epoch 18: 25 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 24 / 36
Epoch 10: 23 / 36
Epoch 11: 16 / 36
Epoch 12: 11 / 36
Epoch 17: 26 / 36
Epoch 18: 24 / 36
Epoch 19: 23 / 36
Result after 20 epoches: 23 / 36  (63%)

===== svm_traindata.txt.1a.Z_0.5_0.5.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_0.5_0.5.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 26 / 68
Epoch 9: 37 / 68
Epoch 10: 37 / 68
Epoch 11: 37 / 68
Epoch 12: 38 / 68
Epoch 17: 36 / 68
Epoch 18: 37 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_0.5_0.5.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 6 / 68
Epoch 1: 43 / 68
Epoch 2: 38 / 68
Epoch 9: 43 / 68
Epoch 10: 44 / 68
Epoch 11: 44 / 68
Epoch 12: 34 / 68
Epoch 17: 37 / 68
Epoch 18: 34 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_0.5_0.5.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 26 / 68
Epoch 9: 37 / 68
Epoch 10: 37 / 68
Epoch 11: 37 / 68
Epoch 12: 37 / 68
Epoch 17: 43 / 68
Epoch 18: 37 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_0.5_0.5.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 1 / 68
Epoch 9: 40 / 68
Epoch 10: 37 / 68
Epoch 11: 42 / 68
Epoch 12: 40 / 68
Epoch 17: 39 / 68
Epoch 18: 43 / 68
Epoch 19: 41 / 68
Result after 20 epoches: 41 / 68  (60%)

===== svm_traindata.txt.1a.Z_0.5_0.5.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 38 / 68
Epoch 10: 36 / 68
Epoch 11: 39 / 68
Epoch 12: 40 / 68
Epoch 17: 36 / 68
Epoch 18: 38 / 68
Epoch 19: 40 / 68
Result after 20 epoches: 40 / 68  (58%)

===== svm_traindata.txt.1a.Z_0.5_0.5.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 30 / 68
Epoch 10: 38 / 68
Epoch 11: 37 / 68
Epoch 12: 26 / 68
Epoch 17: 36 / 68
Epoch 18: 26 / 68
Epoch 19: 29 / 68
Result after 20 epoches: 29 / 68  (42%)

===== svm_traindata.txt.1a.Z_1.5_1.5.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_1.5_1.5.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 26 / 68
Epoch 18: 36 / 68
Epoch 19: 36 / 68
Result after 20 epoches: 36 / 68  (52%)

===== svm_traindata.txt.1a.Z_1.5_1.5.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 37 / 68
Epoch 2: 37 / 68
Epoch 9: 43 / 68
Epoch 10: 37 / 68
Epoch 11: 37 / 68
Epoch 12: 39 / 68
Epoch 17: 37 / 68
Epoch 18: 37 / 68
Epoch 19: 39 / 68
Result after 20 epoches: 39 / 68  (57%)

===== svm_traindata.txt.1a.Z_1.5_1.5.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 11 / 68
Epoch 1: 40 / 68
Epoch 2: 46 / 68
Epoch 9: 38 / 68
Epoch 10: 37 / 68
Epoch 11: 37 / 68
Epoch 12: 37 / 68
Epoch 17: 40 / 68
Epoch 18: 37 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_1.5_1.5.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 16 / 68
Epoch 2: 17 / 68
Epoch 9: 31 / 68
Epoch 10: 39 / 68
Epoch 11: 40 / 68
Epoch 12: 39 / 68
Epoch 17: 38 / 68
Epoch 18: 36 / 68
Epoch 19: 40 / 68
Result after 20 epoches: 40 / 68  (58%)

===== svm_traindata.txt.1a.Z_1.5_1.5.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 42 / 68
Epoch 12: 37 / 68
Epoch 17: 37 / 68
Epoch 18: 42 / 68
Epoch 19: 42 / 68
Result after 20 epoches: 42 / 68  (61%)

===== svm_traindata.txt.1a.Z_1.5_1.5.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 37 / 68
Epoch 10: 37 / 68
Epoch 11: 26 / 68
Epoch 12: 37 / 68
Epoch 17: 26 / 68
Epoch 18: 34 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_2.4_2.4.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 37 / 68
Epoch 10: 26 / 68
Epoch 11: 37 / 68
Epoch 12: 37 / 68
Epoch 17: 37 / 68
Epoch 18: 36 / 68
Epoch 19: 36 / 68
Result after 20 epoches: 36 / 68  (52%)

===== svm_traindata.txt.1a.Z_2.4_2.4.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 26 / 68
Epoch 1: 26 / 68
Epoch 2: 26 / 68
Epoch 9: 26 / 68
Epoch 10: 26 / 68
Epoch 11: 26 / 68
Epoch 12: 26 / 68
Epoch 17: 26 / 68
Epoch 18: 26 / 68
Epoch 19: 26 / 68
Result after 20 epoches: 26 / 68  (38%)

===== svm_traindata.txt.1a.Z_2.4_2.4.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 37 / 68
Epoch 10: 40 / 68
Epoch 11: 37 / 68
Epoch 12: 40 / 68
Epoch 17: 40 / 68
Epoch 18: 40 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_2.4_2.4.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 13 / 68
Epoch 9: 45 / 68
Epoch 10: 37 / 68
Epoch 11: 37 / 68
Epoch 12: 37 / 68
Epoch 17: 41 / 68
Epoch 18: 37 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_2.4_2.4.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 13 / 68
Epoch 1: 14 / 68
Epoch 2: 14 / 68
Epoch 9: 40 / 68
Epoch 10: 39 / 68
Epoch 11: 39 / 68
Epoch 12: 26 / 68
Epoch 17: 37 / 68
Epoch 18: 39 / 68
Epoch 19: 38 / 68
Result after 20 epoches: 38 / 68  (55%)

===== svm_traindata.txt.1a.Z_2.4_2.4.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 41 / 68
Epoch 2: 41 / 68
Epoch 9: 40 / 68
Epoch 10: 43 / 68
Epoch 11: 39 / 68
Epoch 12: 38 / 68
Epoch 17: 38 / 68
Epoch 18: 38 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_2.4_2.4.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 37 / 68
Epoch 1: 34 / 68
Epoch 2: 37 / 68
Epoch 9: 37 / 68
Epoch 10: 35 / 68
Epoch 11: 37 / 68
Epoch 12: 35 / 68
Epoch 17: 37 / 68
Epoch 18: 26 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_3.4_3.4.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 37 / 68
Epoch 10: 25 / 68
Epoch 11: 37 / 68
Epoch 12: 37 / 68
Epoch 17: 26 / 68
Epoch 18: 37 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_3.4_3.4.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 37 / 68
Epoch 10: 37 / 68
Epoch 11: 37 / 68
Epoch 12: 37 / 68
Epoch 17: 37 / 68
Epoch 18: 37 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_3.4_3.4.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 37 / 68
Epoch 10: 42 / 68
Epoch 11: 39 / 68
Epoch 12: 24 / 68
Epoch 17: 41 / 68
Epoch 18: 41 / 68
Epoch 19: 41 / 68
Result after 20 epoches: 41 / 68  (60%)

===== svm_traindata.txt.1a.Z_3.4_3.4.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 5 / 68
Epoch 1: 42 / 68
Epoch 2: 42 / 68
Epoch 9: 39 / 68
Epoch 10: 37 / 68
Epoch 11: 42 / 68
Epoch 12: 37 / 68
Epoch 17: 41 / 68
Epoch 18: 43 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_3.4_3.4.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 5 / 68
Epoch 1: 5 / 68
Epoch 2: 14 / 68
Epoch 9: 25 / 68
Epoch 10: 38 / 68
Epoch 11: 38 / 68
Epoch 12: 37 / 68
Epoch 17: 37 / 68
Epoch 18: 37 / 68
Epoch 19: 40 / 68
Result after 20 epoches: 40 / 68  (58%)

===== svm_traindata.txt.1a.Z_3.4_3.4.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_3.4_3.4.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 25 / 68
Epoch 10: 25 / 68
Epoch 11: 25 / 68
Epoch 12: 25 / 68
Epoch 17: 37 / 68
Epoch 18: 37 / 68
Epoch 19: 25 / 68
Result after 20 epoches: 25 / 68  (36%)

===== svm_traindata.txt.1a.Z_4.3_4.3.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 2 / 68
Epoch 11: 0 / 68
Epoch 12: 29 / 68
Epoch 17: 37 / 68
Epoch 18: 37 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_4.3_4.3.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_4.3_4.3.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 16 / 68
Epoch 2: 37 / 68
Epoch 9: 37 / 68
Epoch 10: 37 / 68
Epoch 11: 42 / 68
Epoch 12: 42 / 68
Epoch 17: 37 / 68
Epoch 18: 39 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_4.3_4.3.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 37 / 68
Epoch 1: 37 / 68
Epoch 2: 37 / 68
Epoch 9: 37 / 68
Epoch 10: 37 / 68
Epoch 11: 43 / 68
Epoch 12: 37 / 68
Epoch 17: 43 / 68
Epoch 18: 42 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_4.3_4.3.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 1 / 68
Epoch 2: 13 / 68
Epoch 9: 39 / 68
Epoch 10: 38 / 68
Epoch 11: 39 / 68
Epoch 12: 36 / 68
Epoch 17: 40 / 68
Epoch 18: 38 / 68
Epoch 19: 36 / 68
Result after 20 epoches: 36 / 68  (52%)

===== svm_traindata.txt.1a.Z_4.3_4.3.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 14 / 68
Epoch 1: 15 / 68
Epoch 2: 37 / 68
Epoch 9: 37 / 68
Epoch 10: 41 / 68
Epoch 11: 42 / 68
Epoch 12: 42 / 68
Epoch 17: 37 / 68
Epoch 18: 37 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_4.3_4.3.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_6.0_6.0.max.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 37 / 68
Epoch 10: 37 / 68
Epoch 11: 37 / 68
Epoch 12: 37 / 68
Epoch 17: 37 / 68
Epoch 18: 29 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_6.0_6.0.max5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 37 / 68
Epoch 18: 37 / 68
Epoch 19: 29 / 68
Result after 20 epoches: 29 / 68  (42%)

===== svm_traindata.txt.1a.Z_6.0_6.0.mean.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 3 / 68
Epoch 1: 44 / 68
Epoch 2: 37 / 68
Epoch 9: 44 / 68
Epoch 10: 37 / 68
Epoch 11: 42 / 68
Epoch 12: 37 / 68
Epoch 17: 44 / 68
Epoch 18: 44 / 68
Epoch 19: 42 / 68
Result after 20 epoches: 42 / 68  (61%)

===== svm_traindata.txt.1a.Z_6.0_6.0.mid.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 2 / 68
Epoch 1: 42 / 68
Epoch 2: 37 / 68
Epoch 9: 37 / 68
Epoch 10: 40 / 68
Epoch 11: 37 / 68
Epoch 12: 37 / 68
Epoch 17: 37 / 68
Epoch 18: 38 / 68
Epoch 19: 42 / 68
Result after 20 epoches: 42 / 68  (61%)

===== svm_traindata.txt.1a.Z_6.0_6.0.min.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 31 / 68
Epoch 10: 37 / 68
Epoch 11: 30 / 68
Epoch 12: 30 / 68
Epoch 17: 34 / 68
Epoch 18: 33 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

===== svm_traindata.txt.1a.Z_6.0_6.0.min5.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 10 / 68
Epoch 1: 37 / 68
Epoch 2: 38 / 68
Epoch 9: 37 / 68
Epoch 10: 37 / 68
Epoch 11: 37 / 68
Epoch 12: 38 / 68
Epoch 17: 31 / 68
Epoch 18: 26 / 68
Epoch 19: 36 / 68
Result after 20 epoches: 36 / 68  (52%)

===== svm_traindata.txt.1a.Z_6.0_6.0.sd.HourlyAggr.fuzzy =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 37 / 68
Epoch 10: 26 / 68
Epoch 11: 37 / 68
Epoch 12: 37 / 68
Epoch 17: 26 / 68
Epoch 18: 37 / 68
Epoch 19: 37 / 68
Result after 20 epoches: 37 / 68  (54%)

