===== Training file list =====
svm_traindata.txt.1a.Z_0.5_6.0
svm_traindata.txt.1a.HC_0.5_0.5
svm_traindata.txt.1a.KDP_0.5_6.0
svm_traindata.txt.1a.SRM_0.5_0.5
svm_traindata.txt.1a.Z_0.5_0.5
svm_traindata.txt.1a.V_0.5_6.0
svm_traindata.txt.1a.CC_0.5_6.0
svm_traindata.txt.1a.CC_0.5_0.5
svm_traindata.txt.1a.ZDR_0.5_6.0
svm_traindata.txt.1a.DAA_0.0_0.0
svm_traindata.txt.1a.KDP_0.5_0.5
svm_traindata.txt.1a.ZDR_0.5_0.5
svm_traindata.txt.1a.SRM_0.5_6.0
svm_traindata.txt.1a.HC_0.5_6.0
svm_traindata.txt.1a.V_0.5_0.5
training_data_dir: /home/awips/sample_data/svmdata.10minPrecipAsLabel/svm_case1_merged_typhoon
rainfall_min_value: 0
rainfall_max_value: 100
n_rainfall_indexes(Number of neurons for output-layer): 100
size_hidden_layer(Number of neurons for hidden-layer): 30
kernel type: Sigmoid
epoches: 30
mini_batch_size: 10
training_rate: 2.0
===== svm_traindata.txt.1a.Z_0.5_6.0 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 1488  test examples: 1488
Epoch 0: 673 / 1488
Epoch 1: 453 / 1488
Epoch 2: 721 / 1488
Epoch 14: 733 / 1488
Epoch 15: 723 / 1488
Epoch 16: 412 / 1488
Epoch 17: 512 / 1488
Epoch 27: 719 / 1488
Epoch 28: 541 / 1488
Epoch 29: 570 / 1488
Result after 30 epoches: 570 / 1488  (38%)

===== svm_traindata.txt.1a.HC_0.5_0.5 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 105  test examples: 105
Epoch 0: 0 / 105
Epoch 1: 0 / 105
Epoch 2: 0 / 105
Epoch 14: 10 / 105
Epoch 15: 47 / 105
Epoch 16: 47 / 105
Epoch 17: 12 / 105
Epoch 27: 47 / 105
Epoch 28: 17 / 105
Epoch 29: 17 / 105
Result after 30 epoches: 17 / 105  (16%)

===== svm_traindata.txt.1a.KDP_0.5_6.0 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 390  test examples: 390
Epoch 0: 0 / 390
Epoch 1: 0 / 390
Epoch 2: 0 / 390
Epoch 14: 167 / 390
Epoch 15: 168 / 390
Epoch 16: 58 / 390
Epoch 17: 169 / 390
Epoch 27: 98 / 390
Epoch 28: 169 / 390
Epoch 29: 92 / 390
Result after 30 epoches: 92 / 390  (23%)

===== svm_traindata.txt.1a.SRM_0.5_0.5 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 105  test examples: 105
Epoch 0: 0 / 105
Epoch 1: 0 / 105
Epoch 2: 0 / 105
Epoch 14: 0 / 105
Epoch 15: 0 / 105
Epoch 16: 0 / 105
Epoch 17: 0 / 105
Epoch 27: 6 / 105
Epoch 28: 39 / 105
Epoch 29: 10 / 105
Result after 30 epoches: 10 / 105  (9%)

===== svm_traindata.txt.1a.Z_0.5_0.5 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 450  test examples: 450
Epoch 0: 13 / 450
Epoch 1: 114 / 450
Epoch 2: 165 / 450
Epoch 14: 166 / 450
Epoch 15: 173 / 450
Epoch 16: 105 / 450
Epoch 17: 126 / 450
Epoch 27: 178 / 450
Epoch 28: 177 / 450
Epoch 29: 105 / 450
Result after 30 epoches: 105 / 450  (23%)

===== svm_traindata.txt.1a.V_0.5_6.0 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 1482  test examples: 1482
Epoch 0: 478 / 1482
Epoch 1: 404 / 1482
Epoch 2: 471 / 1482
Epoch 14: 684 / 1482
Epoch 15: 499 / 1482
Epoch 16: 433 / 1482
Epoch 17: 430 / 1482
Epoch 27: 678 / 1482
Epoch 28: 510 / 1482
Epoch 29: 674 / 1482
Result after 30 epoches: 674 / 1482  (45%)

===== svm_traindata.txt.1a.CC_0.5_6.0 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 390  test examples: 390
Epoch 0: 2 / 390
Epoch 1: 2 / 390
Epoch 2: 1 / 390
Epoch 14: 0 / 390
Epoch 15: 0 / 390
Epoch 16: 0 / 390
Epoch 17: 0 / 390
Epoch 27: 0 / 390
Epoch 28: 0 / 390
Epoch 29: 0 / 390
Result after 30 epoches: 0 / 390  (0%)

===== svm_traindata.txt.1a.CC_0.5_0.5 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 105  test examples: 105
Epoch 0: 0 / 105
Epoch 1: 0 / 105
Epoch 2: 0 / 105
Epoch 14: 0 / 105
Epoch 15: 0 / 105
Epoch 16: 0 / 105
Epoch 17: 0 / 105
Epoch 27: 0 / 105
Epoch 28: 0 / 105
Epoch 29: 0 / 105
Result after 30 epoches: 0 / 105  (0%)

===== svm_traindata.txt.1a.ZDR_0.5_6.0 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 390  test examples: 390
Epoch 0: 0 / 390
Epoch 1: 2 / 390
Epoch 2: 1 / 390
Epoch 14: 165 / 390
Epoch 15: 101 / 390
Epoch 16: 161 / 390
Epoch 17: 163 / 390
Epoch 27: 162 / 390
Epoch 28: 156 / 390
Epoch 29: 160 / 390
Result after 30 epoches: 160 / 390  (41%)

===== svm_traindata.txt.1a.DAA_0.0_0.0 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 104  test examples: 104
Epoch 0: 0 / 104
Epoch 1: 8 / 104
Epoch 2: 8 / 104
Epoch 14: 13 / 104
Epoch 15: 10 / 104
Epoch 16: 7 / 104
Epoch 17: 13 / 104
Epoch 27: 14 / 104
Epoch 28: 16 / 104
Epoch 29: 13 / 104
Result after 30 epoches: 13 / 104  (12%)

===== svm_traindata.txt.1a.KDP_0.5_0.5 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 105  test examples: 105
Epoch 0: 0 / 105
Epoch 1: 0 / 105
Epoch 2: 0 / 105
Epoch 14: 17 / 105
Epoch 15: 6 / 105
Epoch 16: 30 / 105
Epoch 17: 8 / 105
Epoch 27: 7 / 105
Epoch 28: 48 / 105
Epoch 29: 49 / 105
Result after 30 epoches: 49 / 105  (46%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 105  test examples: 105
Epoch 0: 0 / 105
Epoch 1: 1 / 105
Epoch 2: 1 / 105
Epoch 14: 48 / 105
Epoch 15: 30 / 105
Epoch 16: 48 / 105
Epoch 17: 49 / 105
Epoch 27: 50 / 105
Epoch 28: 51 / 105
Epoch 29: 42 / 105
Result after 30 epoches: 42 / 105  (40%)

===== svm_traindata.txt.1a.SRM_0.5_6.0 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 390  test examples: 390
Epoch 0: 0 / 390
Epoch 1: 3 / 390
Epoch 2: 22 / 390
Epoch 14: 129 / 390
Epoch 15: 134 / 390
Epoch 16: 133 / 390
Epoch 17: 130 / 390
Epoch 27: 59 / 390
Epoch 28: 133 / 390
Epoch 29: 161 / 390
Result after 30 epoches: 161 / 390  (41%)

===== svm_traindata.txt.1a.HC_0.5_6.0 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 390  test examples: 390
Epoch 0: 0 / 390
Epoch 1: 0 / 390
Epoch 2: 0 / 390
Epoch 14: 0 / 390
Epoch 15: 0 / 390
Epoch 16: 0 / 390
Epoch 17: 0 / 390
Epoch 27: 160 / 390
Epoch 28: 162 / 390
Epoch 29: 40 / 390
Result after 30 epoches: 40 / 390  (10%)

===== svm_traindata.txt.1a.V_0.5_0.5 =====
dimension(Number of neurons for input layer) : 25
number of training examples: 449  test examples: 449
Epoch 0: 0 / 449
Epoch 1: 72 / 449
Epoch 2: 144 / 449
Epoch 14: 81 / 449
Epoch 15: 94 / 449
Epoch 16: 90 / 449
Epoch 17: 76 / 449
Epoch 27: 162 / 449
Epoch 28: 80 / 449
Epoch 29: 79 / 449
Result after 30 epoches: 79 / 449  (17%)

