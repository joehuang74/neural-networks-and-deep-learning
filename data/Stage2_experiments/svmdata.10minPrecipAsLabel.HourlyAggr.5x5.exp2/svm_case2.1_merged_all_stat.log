===== Training file list =====
svm_traindata.txt.1a.KDP_0.5_0.5.max.HourlyAggr
svm_traindata.txt.1a.KDP_0.5_0.5.max5.HourlyAggr
svm_traindata.txt.1a.KDP_0.5_0.5.mean.HourlyAggr
svm_traindata.txt.1a.KDP_0.5_0.5.mid.HourlyAggr
svm_traindata.txt.1a.KDP_0.5_0.5.min.HourlyAggr
svm_traindata.txt.1a.KDP_0.5_0.5.min5.HourlyAggr
svm_traindata.txt.1a.KDP_0.5_0.5.sd.HourlyAggr
svm_traindata.txt.1a.KDP_1.5_1.5.max.HourlyAggr
svm_traindata.txt.1a.KDP_1.5_1.5.max5.HourlyAggr
svm_traindata.txt.1a.KDP_1.5_1.5.mean.HourlyAggr
svm_traindata.txt.1a.KDP_1.5_1.5.mid.HourlyAggr
svm_traindata.txt.1a.KDP_1.5_1.5.min.HourlyAggr
svm_traindata.txt.1a.KDP_1.5_1.5.min5.HourlyAggr
svm_traindata.txt.1a.KDP_1.5_1.5.sd.HourlyAggr
svm_traindata.txt.1a.KDP_2.4_2.4.max.HourlyAggr
svm_traindata.txt.1a.KDP_2.4_2.4.max5.HourlyAggr
svm_traindata.txt.1a.KDP_2.4_2.4.mean.HourlyAggr
svm_traindata.txt.1a.KDP_2.4_2.4.mid.HourlyAggr
svm_traindata.txt.1a.KDP_2.4_2.4.min.HourlyAggr
svm_traindata.txt.1a.KDP_2.4_2.4.min5.HourlyAggr
svm_traindata.txt.1a.KDP_2.4_2.4.sd.HourlyAggr
svm_traindata.txt.1a.KDP_3.4_3.4.max.HourlyAggr
svm_traindata.txt.1a.KDP_3.4_3.4.max5.HourlyAggr
svm_traindata.txt.1a.KDP_3.4_3.4.mean.HourlyAggr
svm_traindata.txt.1a.KDP_3.4_3.4.mid.HourlyAggr
svm_traindata.txt.1a.KDP_3.4_3.4.min.HourlyAggr
svm_traindata.txt.1a.KDP_3.4_3.4.min5.HourlyAggr
svm_traindata.txt.1a.KDP_3.4_3.4.sd.HourlyAggr
svm_traindata.txt.1a.KDP_4.3_4.3.max.HourlyAggr
svm_traindata.txt.1a.KDP_4.3_4.3.max5.HourlyAggr
svm_traindata.txt.1a.KDP_4.3_4.3.mean.HourlyAggr
svm_traindata.txt.1a.KDP_4.3_4.3.mid.HourlyAggr
svm_traindata.txt.1a.KDP_4.3_4.3.min.HourlyAggr
svm_traindata.txt.1a.KDP_4.3_4.3.min5.HourlyAggr
svm_traindata.txt.1a.KDP_4.3_4.3.sd.HourlyAggr
svm_traindata.txt.1a.KDP_6.0_6.0.max.HourlyAggr
svm_traindata.txt.1a.KDP_6.0_6.0.max5.HourlyAggr
svm_traindata.txt.1a.KDP_6.0_6.0.mean.HourlyAggr
svm_traindata.txt.1a.KDP_6.0_6.0.mid.HourlyAggr
svm_traindata.txt.1a.KDP_6.0_6.0.min.HourlyAggr
svm_traindata.txt.1a.KDP_6.0_6.0.min5.HourlyAggr
svm_traindata.txt.1a.KDP_6.0_6.0.sd.HourlyAggr
svm_traindata.txt.1a.ZDR_0.5_0.5.max.HourlyAggr
svm_traindata.txt.1a.ZDR_0.5_0.5.max5.HourlyAggr
svm_traindata.txt.1a.ZDR_0.5_0.5.mean.HourlyAggr
svm_traindata.txt.1a.ZDR_0.5_0.5.mid.HourlyAggr
svm_traindata.txt.1a.ZDR_0.5_0.5.min.HourlyAggr
svm_traindata.txt.1a.ZDR_0.5_0.5.min5.HourlyAggr
svm_traindata.txt.1a.ZDR_0.5_0.5.sd.HourlyAggr
svm_traindata.txt.1a.ZDR_1.5_1.5.max.HourlyAggr
svm_traindata.txt.1a.ZDR_1.5_1.5.max5.HourlyAggr
svm_traindata.txt.1a.ZDR_1.5_1.5.mean.HourlyAggr
svm_traindata.txt.1a.ZDR_1.5_1.5.mid.HourlyAggr
svm_traindata.txt.1a.ZDR_1.5_1.5.min.HourlyAggr
svm_traindata.txt.1a.ZDR_1.5_1.5.min5.HourlyAggr
svm_traindata.txt.1a.ZDR_1.5_1.5.sd.HourlyAggr
svm_traindata.txt.1a.ZDR_2.4_2.4.max.HourlyAggr
svm_traindata.txt.1a.ZDR_2.4_2.4.max5.HourlyAggr
svm_traindata.txt.1a.ZDR_2.4_2.4.mean.HourlyAggr
svm_traindata.txt.1a.ZDR_2.4_2.4.mid.HourlyAggr
svm_traindata.txt.1a.ZDR_2.4_2.4.min.HourlyAggr
svm_traindata.txt.1a.ZDR_2.4_2.4.min5.HourlyAggr
svm_traindata.txt.1a.ZDR_2.4_2.4.sd.HourlyAggr
svm_traindata.txt.1a.ZDR_3.4_3.4.max.HourlyAggr
svm_traindata.txt.1a.ZDR_3.4_3.4.max5.HourlyAggr
svm_traindata.txt.1a.ZDR_3.4_3.4.mean.HourlyAggr
svm_traindata.txt.1a.ZDR_3.4_3.4.mid.HourlyAggr
svm_traindata.txt.1a.ZDR_3.4_3.4.min.HourlyAggr
svm_traindata.txt.1a.ZDR_3.4_3.4.min5.HourlyAggr
svm_traindata.txt.1a.ZDR_3.4_3.4.sd.HourlyAggr
svm_traindata.txt.1a.ZDR_4.3_4.3.max.HourlyAggr
svm_traindata.txt.1a.ZDR_4.3_4.3.max5.HourlyAggr
svm_traindata.txt.1a.ZDR_4.3_4.3.mean.HourlyAggr
svm_traindata.txt.1a.ZDR_4.3_4.3.mid.HourlyAggr
svm_traindata.txt.1a.ZDR_4.3_4.3.min.HourlyAggr
svm_traindata.txt.1a.ZDR_4.3_4.3.min5.HourlyAggr
svm_traindata.txt.1a.ZDR_4.3_4.3.sd.HourlyAggr
svm_traindata.txt.1a.ZDR_6.0_6.0.max.HourlyAggr
svm_traindata.txt.1a.ZDR_6.0_6.0.max5.HourlyAggr
svm_traindata.txt.1a.ZDR_6.0_6.0.mean.HourlyAggr
svm_traindata.txt.1a.ZDR_6.0_6.0.mid.HourlyAggr
svm_traindata.txt.1a.ZDR_6.0_6.0.min.HourlyAggr
svm_traindata.txt.1a.ZDR_6.0_6.0.min5.HourlyAggr
svm_traindata.txt.1a.ZDR_6.0_6.0.sd.HourlyAggr
svm_traindata.txt.1a.Z_0.5_0.5.max.HourlyAggr
svm_traindata.txt.1a.Z_0.5_0.5.max5.HourlyAggr
svm_traindata.txt.1a.Z_0.5_0.5.mean.HourlyAggr
svm_traindata.txt.1a.Z_0.5_0.5.mid.HourlyAggr
svm_traindata.txt.1a.Z_0.5_0.5.min.HourlyAggr
svm_traindata.txt.1a.Z_0.5_0.5.min5.HourlyAggr
svm_traindata.txt.1a.Z_0.5_0.5.sd.HourlyAggr
svm_traindata.txt.1a.Z_1.5_1.5.max.HourlyAggr
svm_traindata.txt.1a.Z_1.5_1.5.max5.HourlyAggr
svm_traindata.txt.1a.Z_1.5_1.5.mean.HourlyAggr
svm_traindata.txt.1a.Z_1.5_1.5.mid.HourlyAggr
svm_traindata.txt.1a.Z_1.5_1.5.min.HourlyAggr
svm_traindata.txt.1a.Z_1.5_1.5.min5.HourlyAggr
svm_traindata.txt.1a.Z_1.5_1.5.sd.HourlyAggr
svm_traindata.txt.1a.Z_2.4_2.4.max.HourlyAggr
svm_traindata.txt.1a.Z_2.4_2.4.max5.HourlyAggr
svm_traindata.txt.1a.Z_2.4_2.4.mean.HourlyAggr
svm_traindata.txt.1a.Z_2.4_2.4.mid.HourlyAggr
svm_traindata.txt.1a.Z_2.4_2.4.min.HourlyAggr
svm_traindata.txt.1a.Z_2.4_2.4.min5.HourlyAggr
svm_traindata.txt.1a.Z_2.4_2.4.sd.HourlyAggr
svm_traindata.txt.1a.Z_3.4_3.4.max.HourlyAggr
svm_traindata.txt.1a.Z_3.4_3.4.max5.HourlyAggr
svm_traindata.txt.1a.Z_3.4_3.4.mean.HourlyAggr
svm_traindata.txt.1a.Z_3.4_3.4.mid.HourlyAggr
svm_traindata.txt.1a.Z_3.4_3.4.min.HourlyAggr
svm_traindata.txt.1a.Z_3.4_3.4.min5.HourlyAggr
svm_traindata.txt.1a.Z_3.4_3.4.sd.HourlyAggr
svm_traindata.txt.1a.Z_4.3_4.3.max.HourlyAggr
svm_traindata.txt.1a.Z_4.3_4.3.max5.HourlyAggr
svm_traindata.txt.1a.Z_4.3_4.3.mean.HourlyAggr
svm_traindata.txt.1a.Z_4.3_4.3.mid.HourlyAggr
svm_traindata.txt.1a.Z_4.3_4.3.min.HourlyAggr
svm_traindata.txt.1a.Z_4.3_4.3.min5.HourlyAggr
svm_traindata.txt.1a.Z_4.3_4.3.sd.HourlyAggr
svm_traindata.txt.1a.Z_6.0_6.0.max.HourlyAggr
svm_traindata.txt.1a.Z_6.0_6.0.max5.HourlyAggr
svm_traindata.txt.1a.Z_6.0_6.0.mean.HourlyAggr
svm_traindata.txt.1a.Z_6.0_6.0.mid.HourlyAggr
svm_traindata.txt.1a.Z_6.0_6.0.min.HourlyAggr
svm_traindata.txt.1a.Z_6.0_6.0.min5.HourlyAggr
svm_traindata.txt.1a.Z_6.0_6.0.sd.HourlyAggr
training_data_dir: D:\\svmdata.10minPrecipAsLabel.HourlyAggr\svm_case2.1_merged_all_stat
rainfall_min_value: 0
rainfall_max_value: 100
n_rainfall_indexes(Number of neurons for output-layer): 100
size_hidden_layer(Number of neurons for hidden-layer): 30
kernel type: Sigmoid
epoches: 20
mini_batch_size: 10
training_rate: 2.0

===== svm_traindata.txt.1a.KDP_0.5_0.5.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 2 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 0 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 0 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 1 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 0 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 4 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 3 / 36
Epoch 18: 5 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 2 / 36
Result after 20 epoches: 2 / 36  (5%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 4 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 1 / 36
Epoch 2: 5 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 3 / 36
Epoch 18: 0 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 0 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 5 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 0 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 2 / 36
Epoch 10: 0 / 36
Epoch 11: 3 / 36
Epoch 12: 2 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 4 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 4 / 36
Epoch 18: 5 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 0 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 2 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 2 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 4 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 0 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 4 / 36
Epoch 9: 1 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 0 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 2 / 36
Epoch 17: 5 / 36
Epoch 18: 3 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 1 / 36
Epoch 2: 1 / 36
Epoch 9: 1 / 36
Epoch 10: 5 / 36
Epoch 11: 4 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 1 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 4 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 5 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 1 / 36
Result after 20 epoches: 1 / 36  (2%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 3 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 0 / 36
Epoch 18: 3 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 0 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 2 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 1 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 2 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 1 / 36
Epoch 17: 3 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 3 / 36
Epoch 12: 5 / 36
Epoch 17: 3 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 5 / 36
Epoch 9: 0 / 36
Epoch 10: 4 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 4 / 36
Epoch 18: 0 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 1 / 36
Epoch 18: 5 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 4 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 5 / 36
Epoch 1: 5 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 2 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 3 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 4 / 36
Epoch 2: 5 / 36
Epoch 9: 2 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 4 / 36
Epoch 9: 0 / 36
Epoch 10: 5 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 5 / 36
Epoch 18: 0 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 4 / 36
Epoch 18: 5 / 36
Epoch 19: 3 / 36
Result after 20 epoches: 3 / 36  (8%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 4 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 3 / 36
Result after 20 epoches: 3 / 36  (8%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 5 / 36
Epoch 11: 5 / 36
Epoch 12: 0 / 36
Epoch 17: 4 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 3 / 36
Epoch 9: 5 / 36
Epoch 10: 4 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 3 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 5 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 4 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 0 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 4 / 36
Epoch 1: 0 / 36
Epoch 2: 5 / 36
Epoch 9: 5 / 36
Epoch 10: 0 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 1 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 5 / 36
Epoch 10: 4 / 36
Epoch 11: 0 / 36
Epoch 12: 5 / 36
Epoch 17: 5 / 36
Epoch 18: 5 / 36
Epoch 19: 4 / 36
Result after 20 epoches: 4 / 36  (11%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 2 / 36
Epoch 9: 0 / 36
Epoch 10: 2 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 4 / 36
Epoch 18: 5 / 36
Epoch 19: 1 / 36
Result after 20 epoches: 1 / 36  (2%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 3 / 36
Epoch 9: 5 / 36
Epoch 10: 4 / 36
Epoch 11: 5 / 36
Epoch 12: 5 / 36
Epoch 17: 0 / 36
Epoch 18: 5 / 36
Epoch 19: 5 / 36
Result after 20 epoches: 5 / 36  (13%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 143  test examples: 36
Epoch 0: 0 / 36
Epoch 1: 0 / 36
Epoch 2: 0 / 36
Epoch 9: 0 / 36
Epoch 10: 0 / 36
Epoch 11: 0 / 36
Epoch 12: 0 / 36
Epoch 17: 0 / 36
Epoch 18: 0 / 36
Epoch 19: 0 / 36
Result after 20 epoches: 0 / 36  (0%)

===== svm_traindata.txt.1a.Z_0.5_0.5.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 4 / 68
Epoch 2: 4 / 68
Epoch 9: 4 / 68
Epoch 10: 4 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_0.5_0.5.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_0.5_0.5.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 4 / 68
Epoch 2: 6 / 68
Epoch 9: 4 / 68
Epoch 10: 7 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 8 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_0.5_0.5.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 6 / 68
Epoch 2: 4 / 68
Epoch 9: 4 / 68
Epoch 10: 7 / 68
Epoch 11: 7 / 68
Epoch 12: 4 / 68
Epoch 17: 7 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_0.5_0.5.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 3 / 68
Epoch 18: 3 / 68
Epoch 19: 2 / 68
Result after 20 epoches: 2 / 68  (2%)

===== svm_traindata.txt.1a.Z_0.5_0.5.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 1 / 68
Epoch 2: 4 / 68
Epoch 9: 7 / 68
Epoch 10: 7 / 68
Epoch 11: 7 / 68
Epoch 12: 4 / 68
Epoch 17: 7 / 68
Epoch 18: 7 / 68
Epoch 19: 7 / 68
Result after 20 epoches: 7 / 68  (10%)

===== svm_traindata.txt.1a.Z_0.5_0.5.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_1.5_1.5.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_1.5_1.5.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_1.5_1.5.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 1 / 68
Epoch 1: 8 / 68
Epoch 2: 4 / 68
Epoch 9: 4 / 68
Epoch 10: 4 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 6 / 68
Epoch 18: 4 / 68
Epoch 19: 6 / 68
Result after 20 epoches: 6 / 68  (8%)

===== svm_traindata.txt.1a.Z_1.5_1.5.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 2 / 68
Epoch 1: 4 / 68
Epoch 2: 8 / 68
Epoch 9: 4 / 68
Epoch 10: 6 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_1.5_1.5.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 4 / 68
Epoch 2: 4 / 68
Epoch 9: 7 / 68
Epoch 10: 7 / 68
Epoch 11: 8 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 6 / 68
Result after 20 epoches: 6 / 68  (8%)

===== svm_traindata.txt.1a.Z_1.5_1.5.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_1.5_1.5.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 4 / 68
Epoch 1: 4 / 68
Epoch 2: 4 / 68
Epoch 9: 4 / 68
Epoch 10: 4 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_2.4_2.4.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_2.4_2.4.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_2.4_2.4.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 4 / 68
Epoch 2: 4 / 68
Epoch 9: 4 / 68
Epoch 10: 7 / 68
Epoch 11: 4 / 68
Epoch 12: 7 / 68
Epoch 17: 4 / 68
Epoch 18: 6 / 68
Epoch 19: 7 / 68
Result after 20 epoches: 7 / 68  (10%)

===== svm_traindata.txt.1a.Z_2.4_2.4.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 1 / 68
Epoch 1: 7 / 68
Epoch 2: 4 / 68
Epoch 9: 7 / 68
Epoch 10: 4 / 68
Epoch 11: 4 / 68
Epoch 12: 6 / 68
Epoch 17: 4 / 68
Epoch 18: 6 / 68
Epoch 19: 6 / 68
Result after 20 epoches: 6 / 68  (8%)

===== svm_traindata.txt.1a.Z_2.4_2.4.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 3 / 68
Epoch 2: 3 / 68
Epoch 9: 7 / 68
Epoch 10: 4 / 68
Epoch 11: 4 / 68
Epoch 12: 7 / 68
Epoch 17: 7 / 68
Epoch 18: 7 / 68
Epoch 19: 7 / 68
Result after 20 epoches: 7 / 68  (10%)

===== svm_traindata.txt.1a.Z_2.4_2.4.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 4 / 68
Epoch 1: 7 / 68
Epoch 2: 7 / 68
Epoch 9: 4 / 68
Epoch 10: 4 / 68
Epoch 11: 7 / 68
Epoch 12: 3 / 68
Epoch 17: 7 / 68
Epoch 18: 7 / 68
Epoch 19: 6 / 68
Result after 20 epoches: 6 / 68  (8%)

===== svm_traindata.txt.1a.Z_2.4_2.4.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_3.4_3.4.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_3.4_3.4.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 4 / 68
Epoch 11: 4 / 68
Epoch 12: 7 / 68
Epoch 17: 5 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_3.4_3.4.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 1 / 68
Epoch 1: 4 / 68
Epoch 2: 4 / 68
Epoch 9: 7 / 68
Epoch 10: 6 / 68
Epoch 11: 4 / 68
Epoch 12: 6 / 68
Epoch 17: 4 / 68
Epoch 18: 7 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_3.4_3.4.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 3 / 68
Epoch 1: 3 / 68
Epoch 2: 4 / 68
Epoch 9: 6 / 68
Epoch 10: 6 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_3.4_3.4.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_3.4_3.4.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 7 / 68
Epoch 10: 7 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 7 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_3.4_3.4.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_4.3_4.3.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 3 / 68
Epoch 1: 3 / 68
Epoch 2: 4 / 68
Epoch 9: 4 / 68
Epoch 10: 4 / 68
Epoch 11: 6 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 5 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_4.3_4.3.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_4.3_4.3.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 6 / 68
Epoch 9: 4 / 68
Epoch 10: 6 / 68
Epoch 11: 7 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 6 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_4.3_4.3.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 4 / 68
Epoch 10: 4 / 68
Epoch 11: 6 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 6 / 68
Epoch 19: 6 / 68
Result after 20 epoches: 6 / 68  (8%)

===== svm_traindata.txt.1a.Z_4.3_4.3.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 4 / 68
Epoch 1: 4 / 68
Epoch 2: 4 / 68
Epoch 9: 4 / 68
Epoch 10: 7 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 7 / 68
Epoch 19: 6 / 68
Result after 20 epoches: 6 / 68  (8%)

===== svm_traindata.txt.1a.Z_4.3_4.3.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 1 / 68
Epoch 1: 1 / 68
Epoch 2: 4 / 68
Epoch 9: 4 / 68
Epoch 10: 4 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 7 / 68
Result after 20 epoches: 7 / 68  (10%)

===== svm_traindata.txt.1a.Z_4.3_4.3.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_6.0_6.0.max.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 4 / 68
Epoch 1: 4 / 68
Epoch 2: 4 / 68
Epoch 9: 3 / 68
Epoch 10: 4 / 68
Epoch 11: 4 / 68
Epoch 12: 4 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 6 / 68
Result after 20 epoches: 6 / 68  (8%)

===== svm_traindata.txt.1a.Z_6.0_6.0.max5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

===== svm_traindata.txt.1a.Z_6.0_6.0.mean.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 4 / 68
Epoch 2: 2 / 68
Epoch 9: 7 / 68
Epoch 10: 4 / 68
Epoch 11: 6 / 68
Epoch 12: 7 / 68
Epoch 17: 6 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_6.0_6.0.mid.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 2 / 68
Epoch 1: 7 / 68
Epoch 2: 7 / 68
Epoch 9: 7 / 68
Epoch 10: 4 / 68
Epoch 11: 4 / 68
Epoch 12: 6 / 68
Epoch 17: 4 / 68
Epoch 18: 7 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_6.0_6.0.min.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 7 / 68
Epoch 10: 7 / 68
Epoch 11: 4 / 68
Epoch 12: 7 / 68
Epoch 17: 7 / 68
Epoch 18: 4 / 68
Epoch 19: 7 / 68
Result after 20 epoches: 7 / 68  (10%)

===== svm_traindata.txt.1a.Z_6.0_6.0.min5.HourlyAggr =====
dimension(Number of neurons for input layer) : 5
number of training examples: 268  test examples: 68
Epoch 0: 3 / 68
Epoch 1: 7 / 68
Epoch 2: 7 / 68
Epoch 9: 7 / 68
Epoch 10: 7 / 68
Epoch 11: 7 / 68
Epoch 12: 7 / 68
Epoch 17: 4 / 68
Epoch 18: 4 / 68
Epoch 19: 4 / 68
Result after 20 epoches: 4 / 68  (5%)

===== svm_traindata.txt.1a.Z_6.0_6.0.sd.HourlyAggr =====
dimension(Number of neurons for input layer) : 1
number of training examples: 268  test examples: 68
Epoch 0: 0 / 68
Epoch 1: 0 / 68
Epoch 2: 0 / 68
Epoch 9: 0 / 68
Epoch 10: 0 / 68
Epoch 11: 0 / 68
Epoch 12: 0 / 68
Epoch 17: 0 / 68
Epoch 18: 0 / 68
Epoch 19: 0 / 68
Result after 20 epoches: 0 / 68  (0%)

