===== Training file list =====
svm_traindata.txt.1a.KDP_0.5_0.5.max
svm_traindata.txt.1a.KDP_0.5_0.5.max5
svm_traindata.txt.1a.KDP_0.5_0.5.mean
svm_traindata.txt.1a.KDP_0.5_0.5.mid
svm_traindata.txt.1a.KDP_0.5_0.5.min
svm_traindata.txt.1a.KDP_0.5_0.5.min5
svm_traindata.txt.1a.KDP_0.5_0.5.sd
svm_traindata.txt.1a.KDP_1.5_1.5.max
svm_traindata.txt.1a.KDP_1.5_1.5.max5
svm_traindata.txt.1a.KDP_1.5_1.5.mean
svm_traindata.txt.1a.KDP_1.5_1.5.mid
svm_traindata.txt.1a.KDP_1.5_1.5.min
svm_traindata.txt.1a.KDP_1.5_1.5.min5
svm_traindata.txt.1a.KDP_1.5_1.5.sd
svm_traindata.txt.1a.KDP_2.4_2.4.max
svm_traindata.txt.1a.KDP_2.4_2.4.max5
svm_traindata.txt.1a.KDP_2.4_2.4.mean
svm_traindata.txt.1a.KDP_2.4_2.4.mid
svm_traindata.txt.1a.KDP_2.4_2.4.min
svm_traindata.txt.1a.KDP_2.4_2.4.min5
svm_traindata.txt.1a.KDP_2.4_2.4.sd
svm_traindata.txt.1a.KDP_3.4_3.4.max
svm_traindata.txt.1a.KDP_3.4_3.4.max5
svm_traindata.txt.1a.KDP_3.4_3.4.mean
svm_traindata.txt.1a.KDP_3.4_3.4.mid
svm_traindata.txt.1a.KDP_3.4_3.4.min
svm_traindata.txt.1a.KDP_3.4_3.4.min5
svm_traindata.txt.1a.KDP_3.4_3.4.sd
svm_traindata.txt.1a.KDP_4.3_4.3.max
svm_traindata.txt.1a.KDP_4.3_4.3.max5
svm_traindata.txt.1a.KDP_4.3_4.3.mean
svm_traindata.txt.1a.KDP_4.3_4.3.mid
svm_traindata.txt.1a.KDP_4.3_4.3.min
svm_traindata.txt.1a.KDP_4.3_4.3.min5
svm_traindata.txt.1a.KDP_4.3_4.3.sd
svm_traindata.txt.1a.KDP_6.0_6.0.max
svm_traindata.txt.1a.KDP_6.0_6.0.max5
svm_traindata.txt.1a.KDP_6.0_6.0.mean
svm_traindata.txt.1a.KDP_6.0_6.0.mid
svm_traindata.txt.1a.KDP_6.0_6.0.min
svm_traindata.txt.1a.KDP_6.0_6.0.min5
svm_traindata.txt.1a.KDP_6.0_6.0.sd
svm_traindata.txt.1a.ZDR_0.5_0.5.max
svm_traindata.txt.1a.ZDR_0.5_0.5.max5
svm_traindata.txt.1a.ZDR_0.5_0.5.mean
svm_traindata.txt.1a.ZDR_0.5_0.5.mid
svm_traindata.txt.1a.ZDR_0.5_0.5.min
svm_traindata.txt.1a.ZDR_0.5_0.5.min5
svm_traindata.txt.1a.ZDR_0.5_0.5.sd
svm_traindata.txt.1a.ZDR_1.5_1.5.max
svm_traindata.txt.1a.ZDR_1.5_1.5.max5
svm_traindata.txt.1a.ZDR_1.5_1.5.mean
svm_traindata.txt.1a.ZDR_1.5_1.5.mid
svm_traindata.txt.1a.ZDR_1.5_1.5.min
svm_traindata.txt.1a.ZDR_1.5_1.5.min5
svm_traindata.txt.1a.ZDR_1.5_1.5.sd
svm_traindata.txt.1a.ZDR_2.4_2.4.max
svm_traindata.txt.1a.ZDR_2.4_2.4.max5
svm_traindata.txt.1a.ZDR_2.4_2.4.mean
svm_traindata.txt.1a.ZDR_2.4_2.4.mid
svm_traindata.txt.1a.ZDR_2.4_2.4.min
svm_traindata.txt.1a.ZDR_2.4_2.4.min5
svm_traindata.txt.1a.ZDR_2.4_2.4.sd
svm_traindata.txt.1a.ZDR_3.4_3.4.max
svm_traindata.txt.1a.ZDR_3.4_3.4.max5
svm_traindata.txt.1a.ZDR_3.4_3.4.mean
svm_traindata.txt.1a.ZDR_3.4_3.4.mid
svm_traindata.txt.1a.ZDR_3.4_3.4.min
svm_traindata.txt.1a.ZDR_3.4_3.4.min5
svm_traindata.txt.1a.ZDR_3.4_3.4.sd
svm_traindata.txt.1a.ZDR_4.3_4.3.max
svm_traindata.txt.1a.ZDR_4.3_4.3.max5
svm_traindata.txt.1a.ZDR_4.3_4.3.mean
svm_traindata.txt.1a.ZDR_4.3_4.3.mid
svm_traindata.txt.1a.ZDR_4.3_4.3.min
svm_traindata.txt.1a.ZDR_4.3_4.3.min5
svm_traindata.txt.1a.ZDR_4.3_4.3.sd
svm_traindata.txt.1a.ZDR_6.0_6.0.max
svm_traindata.txt.1a.ZDR_6.0_6.0.max5
svm_traindata.txt.1a.ZDR_6.0_6.0.mean
svm_traindata.txt.1a.ZDR_6.0_6.0.mid
svm_traindata.txt.1a.ZDR_6.0_6.0.min
svm_traindata.txt.1a.ZDR_6.0_6.0.min5
svm_traindata.txt.1a.ZDR_6.0_6.0.sd
svm_traindata.txt.1a.Z_0.5_0.5.max
svm_traindata.txt.1a.Z_0.5_0.5.max5
svm_traindata.txt.1a.Z_0.5_0.5.mean
svm_traindata.txt.1a.Z_0.5_0.5.mid
svm_traindata.txt.1a.Z_0.5_0.5.min
svm_traindata.txt.1a.Z_0.5_0.5.min5
svm_traindata.txt.1a.Z_0.5_0.5.sd
svm_traindata.txt.1a.Z_1.5_1.5.max
svm_traindata.txt.1a.Z_1.5_1.5.max5
svm_traindata.txt.1a.Z_1.5_1.5.mean
svm_traindata.txt.1a.Z_1.5_1.5.mid
svm_traindata.txt.1a.Z_1.5_1.5.min
svm_traindata.txt.1a.Z_1.5_1.5.min5
svm_traindata.txt.1a.Z_1.5_1.5.sd
svm_traindata.txt.1a.Z_2.4_2.4.max
svm_traindata.txt.1a.Z_2.4_2.4.max5
svm_traindata.txt.1a.Z_2.4_2.4.mean
svm_traindata.txt.1a.Z_2.4_2.4.mid
svm_traindata.txt.1a.Z_2.4_2.4.min
svm_traindata.txt.1a.Z_2.4_2.4.min5
svm_traindata.txt.1a.Z_2.4_2.4.sd
svm_traindata.txt.1a.Z_3.4_3.4.max
svm_traindata.txt.1a.Z_3.4_3.4.max5
svm_traindata.txt.1a.Z_3.4_3.4.mean
svm_traindata.txt.1a.Z_3.4_3.4.mid
svm_traindata.txt.1a.Z_3.4_3.4.min
svm_traindata.txt.1a.Z_3.4_3.4.min5
svm_traindata.txt.1a.Z_3.4_3.4.sd
svm_traindata.txt.1a.Z_4.3_4.3.max
svm_traindata.txt.1a.Z_4.3_4.3.max5
svm_traindata.txt.1a.Z_4.3_4.3.mean
svm_traindata.txt.1a.Z_4.3_4.3.mid
svm_traindata.txt.1a.Z_4.3_4.3.min
svm_traindata.txt.1a.Z_4.3_4.3.min5
svm_traindata.txt.1a.Z_4.3_4.3.sd
svm_traindata.txt.1a.Z_6.0_6.0.max
svm_traindata.txt.1a.Z_6.0_6.0.max5
svm_traindata.txt.1a.Z_6.0_6.0.mean
svm_traindata.txt.1a.Z_6.0_6.0.mid
svm_traindata.txt.1a.Z_6.0_6.0.min
svm_traindata.txt.1a.Z_6.0_6.0.min5
svm_traindata.txt.1a.Z_6.0_6.0.sd
training_data_dir: D:\\svmdata.10minPrecipAsLabel\svm_case2.1_merged_all_stat
rainfall_min_value: 0
rainfall_max_value: 100
n_rainfall_indexes(Number of neurons for output-layer): 100
size_hidden_layer(Number of neurons for hidden-layer): 30
kernel type: Sigmoid
epoches: 20
mini_batch_size: 10
training_rate: 2.0

===== svm_traindata.txt.1a.KDP_0.5_0.5.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 108 / 287
Epoch 1: 108 / 287
Epoch 2: 108 / 287
Epoch 9: 105 / 287
Epoch 10: 108 / 287
Epoch 11: 106 / 287
Epoch 12: 108 / 287
Epoch 17: 95 / 287
Epoch 18: 106 / 287
Epoch 19: 105 / 287
Result after 20 epoches: 105 / 287  (36%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1145  test examples: 287
Epoch 0: 108 / 287
Epoch 1: 108 / 287
Epoch 2: 108 / 287
Epoch 9: 108 / 287
Epoch 10: 113 / 287
Epoch 11: 110 / 287
Epoch 12: 106 / 287
Epoch 17: 52 / 287
Epoch 18: 111 / 287
Epoch 19: 74 / 287
Result after 20 epoches: 74 / 287  (25%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 0 / 287
Epoch 1: 0 / 287
Epoch 2: 0 / 287
Epoch 9: 0 / 287
Epoch 10: 0 / 287
Epoch 11: 0 / 287
Epoch 12: 0 / 287
Epoch 17: 0 / 287
Epoch 18: 116 / 287
Epoch 19: 108 / 287
Result after 20 epoches: 108 / 287  (37%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 55 / 287
Epoch 1: 108 / 287
Epoch 2: 32 / 287
Epoch 9: 33 / 287
Epoch 10: 109 / 287
Epoch 11: 110 / 287
Epoch 12: 80 / 287
Epoch 17: 109 / 287
Epoch 18: 107 / 287
Epoch 19: 109 / 287
Result after 20 epoches: 109 / 287  (37%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 108 / 287
Epoch 1: 108 / 287
Epoch 2: 32 / 287
Epoch 9: 108 / 287
Epoch 10: 108 / 287
Epoch 11: 108 / 287
Epoch 12: 58 / 287
Epoch 17: 108 / 287
Epoch 18: 108 / 287
Epoch 19: 101 / 287
Result after 20 epoches: 101 / 287  (35%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1145  test examples: 287
Epoch 0: 32 / 287
Epoch 1: 108 / 287
Epoch 2: 108 / 287
Epoch 9: 69 / 287
Epoch 10: 107 / 287
Epoch 11: 33 / 287
Epoch 12: 32 / 287
Epoch 17: 29 / 287
Epoch 18: 72 / 287
Epoch 19: 108 / 287
Result after 20 epoches: 108 / 287  (37%)

===== svm_traindata.txt.1a.KDP_0.5_0.5.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 108 / 287
Epoch 1: 32 / 287
Epoch 2: 108 / 287
Epoch 9: 108 / 287
Epoch 10: 107 / 287
Epoch 11: 40 / 287
Epoch 12: 106 / 287
Epoch 17: 40 / 287
Epoch 18: 94 / 287
Epoch 19: 75 / 287
Result after 20 epoches: 75 / 287  (26%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 110 / 286
Epoch 2: 31 / 286
Epoch 9: 95 / 286
Epoch 10: 109 / 286
Epoch 11: 110 / 286
Epoch 12: 103 / 286
Epoch 17: 104 / 286
Epoch 18: 106 / 286
Epoch 19: 106 / 286
Result after 20 epoches: 106 / 286  (37%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1140  test examples: 286
Epoch 0: 76 / 286
Epoch 1: 110 / 286
Epoch 2: 102 / 286
Epoch 9: 111 / 286
Epoch 10: 75 / 286
Epoch 11: 47 / 286
Epoch 12: 105 / 286
Epoch 17: 108 / 286
Epoch 18: 97 / 286
Epoch 19: 104 / 286
Result after 20 epoches: 104 / 286  (36%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 111 / 286
Epoch 10: 108 / 286
Epoch 11: 112 / 286
Epoch 12: 111 / 286
Epoch 17: 111 / 286
Epoch 18: 112 / 286
Epoch 19: 108 / 286
Result after 20 epoches: 108 / 286  (37%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 43 / 286
Epoch 1: 111 / 286
Epoch 2: 111 / 286
Epoch 9: 111 / 286
Epoch 10: 105 / 286
Epoch 11: 111 / 286
Epoch 12: 111 / 286
Epoch 17: 43 / 286
Epoch 18: 111 / 286
Epoch 19: 105 / 286
Result after 20 epoches: 105 / 286  (36%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 111 / 286
Epoch 2: 111 / 286
Epoch 9: 111 / 286
Epoch 10: 109 / 286
Epoch 11: 31 / 286
Epoch 12: 111 / 286
Epoch 17: 111 / 286
Epoch 18: 111 / 286
Epoch 19: 101 / 286
Result after 20 epoches: 101 / 286  (35%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1140  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 31 / 286
Epoch 10: 31 / 286
Epoch 11: 111 / 286
Epoch 12: 111 / 286
Epoch 17: 111 / 286
Epoch 18: 31 / 286
Epoch 19: 111 / 286
Result after 20 epoches: 111 / 286  (38%)

===== svm_traindata.txt.1a.KDP_1.5_1.5.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 111 / 286
Epoch 2: 111 / 286
Epoch 9: 108 / 286
Epoch 10: 108 / 286
Epoch 11: 109 / 286
Epoch 12: 108 / 286
Epoch 17: 109 / 286
Epoch 18: 31 / 286
Epoch 19: 104 / 286
Result after 20 epoches: 104 / 286  (36%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 52 / 286
Epoch 2: 31 / 286
Epoch 9: 31 / 286
Epoch 10: 48 / 286
Epoch 11: 108 / 286
Epoch 12: 52 / 286
Epoch 17: 52 / 286
Epoch 18: 52 / 286
Epoch 19: 96 / 286
Result after 20 epoches: 96 / 286  (33%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 31 / 286
Epoch 9: 92 / 286
Epoch 10: 59 / 286
Epoch 11: 46 / 286
Epoch 12: 111 / 286
Epoch 17: 112 / 286
Epoch 18: 105 / 286
Epoch 19: 83 / 286
Result after 20 epoches: 83 / 286  (29%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 110 / 286
Epoch 2: 46 / 286
Epoch 9: 31 / 286
Epoch 10: 110 / 286
Epoch 11: 31 / 286
Epoch 12: 110 / 286
Epoch 17: 108 / 286
Epoch 18: 110 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 110 / 286
Epoch 10: 109 / 286
Epoch 11: 31 / 286
Epoch 12: 110 / 286
Epoch 17: 110 / 286
Epoch 18: 31 / 286
Epoch 19: 81 / 286
Result after 20 epoches: 81 / 286  (28%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 93 / 286
Epoch 2: 110 / 286
Epoch 9: 31 / 286
Epoch 10: 48 / 286
Epoch 11: 110 / 286
Epoch 12: 110 / 286
Epoch 17: 108 / 286
Epoch 18: 86 / 286
Epoch 19: 31 / 286
Result after 20 epoches: 31 / 286  (10%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 65 / 286
Epoch 10: 91 / 286
Epoch 11: 107 / 286
Epoch 12: 107 / 286
Epoch 17: 109 / 286
Epoch 18: 63 / 286
Epoch 19: 84 / 286
Result after 20 epoches: 84 / 286  (29%)

===== svm_traindata.txt.1a.KDP_2.4_2.4.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 110 / 286
Epoch 10: 31 / 286
Epoch 11: 110 / 286
Epoch 12: 110 / 286
Epoch 17: 111 / 286
Epoch 18: 110 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 40 / 286
Epoch 2: 110 / 286
Epoch 9: 90 / 286
Epoch 10: 111 / 286
Epoch 11: 111 / 286
Epoch 12: 110 / 286
Epoch 17: 90 / 286
Epoch 18: 104 / 286
Epoch 19: 111 / 286
Result after 20 epoches: 111 / 286  (38%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 57 / 286
Epoch 2: 111 / 286
Epoch 9: 102 / 286
Epoch 10: 99 / 286
Epoch 11: 59 / 286
Epoch 12: 110 / 286
Epoch 17: 58 / 286
Epoch 18: 110 / 286
Epoch 19: 94 / 286
Result after 20 epoches: 94 / 286  (32%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 110 / 286
Epoch 10: 110 / 286
Epoch 11: 96 / 286
Epoch 12: 111 / 286
Epoch 17: 104 / 286
Epoch 18: 87 / 286
Epoch 19: 77 / 286
Result after 20 epoches: 77 / 286  (26%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 110 / 286
Epoch 10: 110 / 286
Epoch 11: 82 / 286
Epoch 12: 110 / 286
Epoch 17: 110 / 286
Epoch 18: 103 / 286
Epoch 19: 101 / 286
Result after 20 epoches: 101 / 286  (35%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 84 / 286
Epoch 2: 110 / 286
Epoch 9: 105 / 286
Epoch 10: 110 / 286
Epoch 11: 31 / 286
Epoch 12: 56 / 286
Epoch 17: 110 / 286
Epoch 18: 110 / 286
Epoch 19: 107 / 286
Result after 20 epoches: 107 / 286  (37%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 31 / 286
Epoch 2: 30 / 286
Epoch 9: 30 / 286
Epoch 10: 40 / 286
Epoch 11: 31 / 286
Epoch 12: 31 / 286
Epoch 17: 41 / 286
Epoch 18: 109 / 286
Epoch 19: 109 / 286
Result after 20 epoches: 109 / 286  (38%)

===== svm_traindata.txt.1a.KDP_3.4_3.4.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 0 / 286
Epoch 10: 0 / 286
Epoch 11: 109 / 286
Epoch 12: 31 / 286
Epoch 17: 109 / 286
Epoch 18: 109 / 286
Epoch 19: 103 / 286
Result after 20 epoches: 103 / 286  (36%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 31 / 286
Epoch 2: 109 / 286
Epoch 9: 31 / 286
Epoch 10: 110 / 286
Epoch 11: 31 / 286
Epoch 12: 45 / 286
Epoch 17: 109 / 286
Epoch 18: 91 / 286
Epoch 19: 31 / 286
Result after 20 epoches: 31 / 286  (10%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1141  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 31 / 286
Epoch 2: 109 / 286
Epoch 9: 31 / 286
Epoch 10: 31 / 286
Epoch 11: 109 / 286
Epoch 12: 110 / 286
Epoch 17: 109 / 286
Epoch 18: 109 / 286
Epoch 19: 69 / 286
Result after 20 epoches: 69 / 286  (24%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 31 / 286
Epoch 10: 110 / 286
Epoch 11: 31 / 286
Epoch 12: 31 / 286
Epoch 17: 110 / 286
Epoch 18: 110 / 286
Epoch 19: 111 / 286
Result after 20 epoches: 111 / 286  (38%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 0 / 286
Epoch 10: 34 / 286
Epoch 11: 110 / 286
Epoch 12: 110 / 286
Epoch 17: 110 / 286
Epoch 18: 111 / 286
Epoch 19: 31 / 286
Result after 20 epoches: 31 / 286  (10%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 31 / 286
Epoch 2: 31 / 286
Epoch 9: 109 / 286
Epoch 10: 31 / 286
Epoch 11: 109 / 286
Epoch 12: 110 / 286
Epoch 17: 31 / 286
Epoch 18: 108 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1141  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 109 / 286
Epoch 2: 110 / 286
Epoch 9: 31 / 286
Epoch 10: 109 / 286
Epoch 11: 109 / 286
Epoch 12: 107 / 286
Epoch 17: 31 / 286
Epoch 18: 110 / 286
Epoch 19: 108 / 286
Result after 20 epoches: 108 / 286  (37%)

===== svm_traindata.txt.1a.KDP_4.3_4.3.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 110 / 286
Epoch 9: 109 / 286
Epoch 10: 109 / 286
Epoch 11: 31 / 286
Epoch 12: 108 / 286
Epoch 17: 109 / 286
Epoch 18: 108 / 286
Epoch 19: 109 / 286
Result after 20 epoches: 109 / 286  (38%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 92 / 286
Epoch 1: 98 / 286
Epoch 2: 109 / 286
Epoch 9: 110 / 286
Epoch 10: 60 / 286
Epoch 11: 109 / 286
Epoch 12: 103 / 286
Epoch 17: 110 / 286
Epoch 18: 106 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1140  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 101 / 286
Epoch 2: 49 / 286
Epoch 9: 102 / 286
Epoch 10: 58 / 286
Epoch 11: 112 / 286
Epoch 12: 77 / 286
Epoch 17: 90 / 286
Epoch 18: 106 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 110 / 286
Epoch 10: 105 / 286
Epoch 11: 110 / 286
Epoch 12: 110 / 286
Epoch 17: 110 / 286
Epoch 18: 110 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 31 / 286
Epoch 10: 95 / 286
Epoch 11: 110 / 286
Epoch 12: 111 / 286
Epoch 17: 111 / 286
Epoch 18: 33 / 286
Epoch 19: 112 / 286
Result after 20 epoches: 112 / 286  (39%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 91 / 286
Epoch 10: 98 / 286
Epoch 11: 62 / 286
Epoch 12: 103 / 286
Epoch 17: 62 / 286
Epoch 18: 109 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1140  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 105 / 286
Epoch 2: 31 / 286
Epoch 9: 105 / 286
Epoch 10: 97 / 286
Epoch 11: 105 / 286
Epoch 12: 96 / 286
Epoch 17: 95 / 286
Epoch 18: 104 / 286
Epoch 19: 80 / 286
Result after 20 epoches: 80 / 286  (27%)

===== svm_traindata.txt.1a.KDP_6.0_6.0.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 31 / 286
Epoch 2: 108 / 286
Epoch 9: 110 / 286
Epoch 10: 57 / 286
Epoch 11: 109 / 286
Epoch 12: 107 / 286
Epoch 17: 101 / 286
Epoch 18: 45 / 286
Epoch 19: 105 / 286
Result after 20 epoches: 105 / 286  (36%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 0 / 287
Epoch 1: 0 / 287
Epoch 2: 0 / 287
Epoch 9: 0 / 287
Epoch 10: 0 / 287
Epoch 11: 0 / 287
Epoch 12: 0 / 287
Epoch 17: 0 / 287
Epoch 18: 0 / 287
Epoch 19: 0 / 287
Result after 20 epoches: 0 / 287  (0%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1145  test examples: 287
Epoch 0: 0 / 287
Epoch 1: 0 / 287
Epoch 2: 0 / 287
Epoch 9: 60 / 287
Epoch 10: 46 / 287
Epoch 11: 108 / 287
Epoch 12: 43 / 287
Epoch 17: 58 / 287
Epoch 18: 57 / 287
Epoch 19: 57 / 287
Result after 20 epoches: 57 / 287  (19%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 36 / 287
Epoch 1: 42 / 287
Epoch 2: 108 / 287
Epoch 9: 108 / 287
Epoch 10: 108 / 287
Epoch 11: 108 / 287
Epoch 12: 108 / 287
Epoch 17: 40 / 287
Epoch 18: 108 / 287
Epoch 19: 108 / 287
Result after 20 epoches: 108 / 287  (37%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 108 / 287
Epoch 1: 35 / 287
Epoch 2: 108 / 287
Epoch 9: 48 / 287
Epoch 10: 48 / 287
Epoch 11: 108 / 287
Epoch 12: 108 / 287
Epoch 17: 46 / 287
Epoch 18: 35 / 287
Epoch 19: 108 / 287
Result after 20 epoches: 108 / 287  (37%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 108 / 287
Epoch 1: 108 / 287
Epoch 2: 108 / 287
Epoch 9: 108 / 287
Epoch 10: 87 / 287
Epoch 11: 60 / 287
Epoch 12: 84 / 287
Epoch 17: 91 / 287
Epoch 18: 94 / 287
Epoch 19: 96 / 287
Result after 20 epoches: 96 / 287  (33%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1145  test examples: 287
Epoch 0: 107 / 287
Epoch 1: 107 / 287
Epoch 2: 102 / 287
Epoch 9: 85 / 287
Epoch 10: 90 / 287
Epoch 11: 108 / 287
Epoch 12: 108 / 287
Epoch 17: 83 / 287
Epoch 18: 59 / 287
Epoch 19: 34 / 287
Result after 20 epoches: 34 / 287  (11%)

===== svm_traindata.txt.1a.ZDR_0.5_0.5.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1145  test examples: 287
Epoch 0: 32 / 287
Epoch 1: 59 / 287
Epoch 2: 57 / 287
Epoch 9: 108 / 287
Epoch 10: 63 / 287
Epoch 11: 106 / 287
Epoch 12: 44 / 287
Epoch 17: 50 / 287
Epoch 18: 108 / 287
Epoch 19: 43 / 287
Result after 20 epoches: 43 / 287  (14%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 57 / 286
Epoch 9: 43 / 286
Epoch 10: 111 / 286
Epoch 11: 111 / 286
Epoch 12: 49 / 286
Epoch 17: 75 / 286
Epoch 18: 62 / 286
Epoch 19: 63 / 286
Result after 20 epoches: 63 / 286  (22%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1140  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 103 / 286
Epoch 2: 61 / 286
Epoch 9: 112 / 286
Epoch 10: 109 / 286
Epoch 11: 71 / 286
Epoch 12: 93 / 286
Epoch 17: 57 / 286
Epoch 18: 56 / 286
Epoch 19: 58 / 286
Result after 20 epoches: 58 / 286  (20%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 111 / 286
Epoch 10: 76 / 286
Epoch 11: 101 / 286
Epoch 12: 76 / 286
Epoch 17: 87 / 286
Epoch 18: 70 / 286
Epoch 19: 111 / 286
Result after 20 epoches: 111 / 286  (38%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 9 / 286
Epoch 1: 15 / 286
Epoch 2: 111 / 286
Epoch 9: 89 / 286
Epoch 10: 111 / 286
Epoch 11: 111 / 286
Epoch 12: 111 / 286
Epoch 17: 111 / 286
Epoch 18: 111 / 286
Epoch 19: 71 / 286
Result after 20 epoches: 71 / 286  (24%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 103 / 286
Epoch 1: 103 / 286
Epoch 2: 111 / 286
Epoch 9: 104 / 286
Epoch 10: 88 / 286
Epoch 11: 82 / 286
Epoch 12: 94 / 286
Epoch 17: 83 / 286
Epoch 18: 88 / 286
Epoch 19: 74 / 286
Result after 20 epoches: 74 / 286  (25%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1140  test examples: 286
Epoch 0: 111 / 286
Epoch 1: 111 / 286
Epoch 2: 102 / 286
Epoch 9: 84 / 286
Epoch 10: 96 / 286
Epoch 11: 77 / 286
Epoch 12: 109 / 286
Epoch 17: 87 / 286
Epoch 18: 84 / 286
Epoch 19: 93 / 286
Result after 20 epoches: 93 / 286  (32%)

===== svm_traindata.txt.1a.ZDR_1.5_1.5.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 286
Epoch 0: 68 / 286
Epoch 1: 111 / 286
Epoch 2: 74 / 286
Epoch 9: 95 / 286
Epoch 10: 110 / 286
Epoch 11: 111 / 286
Epoch 12: 90 / 286
Epoch 17: 72 / 286
Epoch 18: 67 / 286
Epoch 19: 75 / 286
Result after 20 epoches: 75 / 286  (26%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 71 / 286
Epoch 10: 110 / 286
Epoch 11: 87 / 286
Epoch 12: 110 / 286
Epoch 17: 82 / 286
Epoch 18: 83 / 286
Epoch 19: 45 / 286
Result after 20 epoches: 45 / 286  (15%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 84 / 286
Epoch 2: 110 / 286
Epoch 9: 80 / 286
Epoch 10: 71 / 286
Epoch 11: 43 / 286
Epoch 12: 110 / 286
Epoch 17: 53 / 286
Epoch 18: 110 / 286
Epoch 19: 44 / 286
Result after 20 epoches: 44 / 286  (15%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 110 / 286
Epoch 10: 110 / 286
Epoch 11: 110 / 286
Epoch 12: 83 / 286
Epoch 17: 60 / 286
Epoch 18: 34 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 66 / 286
Epoch 10: 110 / 286
Epoch 11: 110 / 286
Epoch 12: 110 / 286
Epoch 17: 31 / 286
Epoch 18: 99 / 286
Epoch 19: 33 / 286
Result after 20 epoches: 33 / 286  (11%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 105 / 286
Epoch 1: 32 / 286
Epoch 2: 62 / 286
Epoch 9: 116 / 286
Epoch 10: 108 / 286
Epoch 11: 56 / 286
Epoch 12: 110 / 286
Epoch 17: 62 / 286
Epoch 18: 102 / 286
Epoch 19: 113 / 286
Result after 20 epoches: 113 / 286  (39%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1142  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 110 / 286
Epoch 2: 107 / 286
Epoch 9: 77 / 286
Epoch 10: 103 / 286
Epoch 11: 102 / 286
Epoch 12: 105 / 286
Epoch 17: 31 / 286
Epoch 18: 92 / 286
Epoch 19: 48 / 286
Result after 20 epoches: 48 / 286  (16%)

===== svm_traindata.txt.1a.ZDR_2.4_2.4.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 74 / 286
Epoch 10: 94 / 286
Epoch 11: 85 / 286
Epoch 12: 70 / 286
Epoch 17: 81 / 286
Epoch 18: 110 / 286
Epoch 19: 73 / 286
Result after 20 epoches: 73 / 286  (25%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 0 / 286
Epoch 10: 0 / 286
Epoch 11: 0 / 286
Epoch 12: 0 / 286
Epoch 17: 0 / 286
Epoch 18: 44 / 286
Epoch 19: 65 / 286
Result after 20 epoches: 65 / 286  (22%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1142  test examples: 286
Epoch 0: 31 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 74 / 286
Epoch 10: 110 / 286
Epoch 11: 110 / 286
Epoch 12: 41 / 286
Epoch 17: 110 / 286
Epoch 18: 106 / 286
Epoch 19: 75 / 286
Result after 20 epoches: 75 / 286  (26%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 0 / 286
Epoch 10: 0 / 286
Epoch 11: 110 / 286
Epoch 12: 110 / 286
Epoch 17: 110 / 286
Epoch 18: 110 / 286
Epoch 19: 31 / 286
Result after 20 epoches: 31 / 286  (10%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 0 / 286
Epoch 10: 0 / 286
Epoch 11: 0 / 286
Epoch 12: 73 / 286
Epoch 17: 60 / 286
Epoch 18: 56 / 286
Epoch 19: 105 / 286
Result after 20 epoches: 105 / 286  (36%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 36 / 286
Epoch 1: 37 / 286
Epoch 2: 109 / 286
Epoch 9: 110 / 286
Epoch 10: 47 / 286
Epoch 11: 110 / 286
Epoch 12: 67 / 286
Epoch 17: 37 / 286
Epoch 18: 108 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 0 / 286
Epoch 9: 106 / 286
Epoch 10: 102 / 286
Epoch 11: 90 / 286
Epoch 12: 109 / 286
Epoch 17: 111 / 286
Epoch 18: 101 / 286
Epoch 19: 104 / 286
Result after 20 epoches: 104 / 286  (36%)

===== svm_traindata.txt.1a.ZDR_3.4_3.4.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1142  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 43 / 286
Epoch 2: 109 / 286
Epoch 9: 110 / 286
Epoch 10: 43 / 286
Epoch 11: 110 / 286
Epoch 12: 110 / 286
Epoch 17: 40 / 286
Epoch 18: 84 / 286
Epoch 19: 43 / 286
Result after 20 epoches: 43 / 286  (15%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 111 / 286
Epoch 10: 110 / 286
Epoch 11: 57 / 286
Epoch 12: 110 / 286
Epoch 17: 110 / 286
Epoch 18: 110 / 286
Epoch 19: 31 / 286
Result after 20 epoches: 31 / 286  (10%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1141  test examples: 286
Epoch 0: 2 / 286
Epoch 1: 110 / 286
Epoch 2: 110 / 286
Epoch 9: 38 / 286
Epoch 10: 66 / 286
Epoch 11: 96 / 286
Epoch 12: 49 / 286
Epoch 17: 65 / 286
Epoch 18: 110 / 286
Epoch 19: 110 / 286
Result after 20 epoches: 110 / 286  (38%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 31 / 286
Epoch 2: 31 / 286
Epoch 9: 32 / 286
Epoch 10: 110 / 286
Epoch 11: 110 / 286
Epoch 12: 48 / 286
Epoch 17: 31 / 286
Epoch 18: 31 / 286
Epoch 19: 31 / 286
Result after 20 epoches: 31 / 286  (10%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 12 / 286
Epoch 1: 12 / 286
Epoch 2: 12 / 286
Epoch 9: 12 / 286
Epoch 10: 12 / 286
Epoch 11: 12 / 286
Epoch 12: 12 / 286
Epoch 17: 12 / 286
Epoch 18: 12 / 286
Epoch 19: 12 / 286
Result after 20 epoches: 12 / 286  (4%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 0 / 286
Epoch 2: 110 / 286
Epoch 9: 110 / 286
Epoch 10: 110 / 286
Epoch 11: 110 / 286
Epoch 12: 57 / 286
Epoch 17: 110 / 286
Epoch 18: 110 / 286
Epoch 19: 31 / 286
Result after 20 epoches: 31 / 286  (10%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1141  test examples: 286
Epoch 0: 110 / 286
Epoch 1: 111 / 286
Epoch 2: 31 / 286
Epoch 9: 31 / 286
Epoch 10: 31 / 286
Epoch 11: 87 / 286
Epoch 12: 110 / 286
Epoch 17: 107 / 286
Epoch 18: 31 / 286
Epoch 19: 65 / 286
Result after 20 epoches: 65 / 286  (22%)

===== svm_traindata.txt.1a.ZDR_4.3_4.3.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1141  test examples: 286
Epoch 0: 0 / 286
Epoch 1: 31 / 286
Epoch 2: 39 / 286
Epoch 9: 110 / 286
Epoch 10: 110 / 286
Epoch 11: 110 / 286
Epoch 12: 110 / 286
Epoch 17: 96 / 286
Epoch 18: 31 / 286
Epoch 19: 31 / 286
Result after 20 epoches: 31 / 286  (10%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 285
Epoch 0: 0 / 285
Epoch 1: 0 / 285
Epoch 2: 67 / 285
Epoch 9: 109 / 285
Epoch 10: 45 / 285
Epoch 11: 109 / 285
Epoch 12: 69 / 285
Epoch 17: 109 / 285
Epoch 18: 46 / 285
Epoch 19: 70 / 285
Result after 20 epoches: 70 / 285  (24%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1140  test examples: 285
Epoch 0: 0 / 285
Epoch 1: 109 / 285
Epoch 2: 44 / 285
Epoch 9: 45 / 285
Epoch 10: 70 / 285
Epoch 11: 102 / 285
Epoch 12: 44 / 285
Epoch 17: 40 / 285
Epoch 18: 39 / 285
Epoch 19: 70 / 285
Result after 20 epoches: 70 / 285  (24%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 285
Epoch 0: 0 / 285
Epoch 1: 0 / 285
Epoch 2: 48 / 285
Epoch 9: 109 / 285
Epoch 10: 109 / 285
Epoch 11: 109 / 285
Epoch 12: 74 / 285
Epoch 17: 109 / 285
Epoch 18: 109 / 285
Epoch 19: 110 / 285
Result after 20 epoches: 110 / 285  (38%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 285
Epoch 0: 36 / 285
Epoch 1: 109 / 285
Epoch 2: 63 / 285
Epoch 9: 109 / 285
Epoch 10: 57 / 285
Epoch 11: 109 / 285
Epoch 12: 63 / 285
Epoch 17: 57 / 285
Epoch 18: 74 / 285
Epoch 19: 109 / 285
Result after 20 epoches: 109 / 285  (38%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 285
Epoch 0: 0 / 285
Epoch 1: 0 / 285
Epoch 2: 109 / 285
Epoch 9: 109 / 285
Epoch 10: 109 / 285
Epoch 11: 109 / 285
Epoch 12: 109 / 285
Epoch 17: 109 / 285
Epoch 18: 109 / 285
Epoch 19: 109 / 285
Result after 20 epoches: 109 / 285  (38%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 1140  test examples: 285
Epoch 0: 109 / 285
Epoch 1: 99 / 285
Epoch 2: 109 / 285
Epoch 9: 108 / 285
Epoch 10: 85 / 285
Epoch 11: 109 / 285
Epoch 12: 105 / 285
Epoch 17: 45 / 285
Epoch 18: 82 / 285
Epoch 19: 36 / 285
Result after 20 epoches: 36 / 285  (12%)

===== svm_traindata.txt.1a.ZDR_6.0_6.0.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 1140  test examples: 285
Epoch 0: 107 / 285
Epoch 1: 65 / 285
Epoch 2: 85 / 285
Epoch 9: 109 / 285
Epoch 10: 85 / 285
Epoch 11: 70 / 285
Epoch 12: 109 / 285
Epoch 17: 85 / 285
Epoch 18: 37 / 285
Epoch 19: 45 / 285
Result after 20 epoches: 45 / 285  (15%)

===== svm_traindata.txt.1a.Z_0.5_0.5.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2200  test examples: 550
Epoch 0: 0 / 550
Epoch 1: 0 / 550
Epoch 2: 57 / 550
Epoch 9: 258 / 550
Epoch 10: 55 / 550
Epoch 11: 55 / 550
Epoch 12: 258 / 550
Epoch 17: 258 / 550
Epoch 18: 57 / 550
Epoch 19: 258 / 550
Result after 20 epoches: 258 / 550  (46%)

===== svm_traindata.txt.1a.Z_0.5_0.5.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2200  test examples: 550
Epoch 0: 258 / 550
Epoch 1: 90 / 550
Epoch 2: 258 / 550
Epoch 9: 258 / 550
Epoch 10: 91 / 550
Epoch 11: 122 / 550
Epoch 12: 258 / 550
Epoch 17: 258 / 550
Epoch 18: 258 / 550
Epoch 19: 258 / 550
Result after 20 epoches: 258 / 550  (46%)

===== svm_traindata.txt.1a.Z_0.5_0.5.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2200  test examples: 550
Epoch 0: 258 / 550
Epoch 1: 258 / 550
Epoch 2: 140 / 550
Epoch 9: 137 / 550
Epoch 10: 258 / 550
Epoch 11: 131 / 550
Epoch 12: 258 / 550
Epoch 17: 258 / 550
Epoch 18: 258 / 550
Epoch 19: 258 / 550
Result after 20 epoches: 258 / 550  (46%)

===== svm_traindata.txt.1a.Z_0.5_0.5.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2200  test examples: 550
Epoch 0: 258 / 550
Epoch 1: 154 / 550
Epoch 2: 258 / 550
Epoch 9: 258 / 550
Epoch 10: 169 / 550
Epoch 11: 183 / 550
Epoch 12: 167 / 550
Epoch 17: 181 / 550
Epoch 18: 258 / 550
Epoch 19: 258 / 550
Result after 20 epoches: 258 / 550  (46%)

===== svm_traindata.txt.1a.Z_0.5_0.5.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2200  test examples: 550
Epoch 0: 214 / 550
Epoch 1: 244 / 550
Epoch 2: 238 / 550
Epoch 9: 169 / 550
Epoch 10: 191 / 550
Epoch 11: 256 / 550
Epoch 12: 231 / 550
Epoch 17: 237 / 550
Epoch 18: 210 / 550
Epoch 19: 223 / 550
Result after 20 epoches: 223 / 550  (40%)

===== svm_traindata.txt.1a.Z_0.5_0.5.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2200  test examples: 550
Epoch 0: 0 / 550
Epoch 1: 0 / 550
Epoch 2: 0 / 550
Epoch 9: 0 / 550
Epoch 10: 0 / 550
Epoch 11: 0 / 550
Epoch 12: 0 / 550
Epoch 17: 0 / 550
Epoch 18: 0 / 550
Epoch 19: 0 / 550
Result after 20 epoches: 0 / 550  (0%)

===== svm_traindata.txt.1a.Z_0.5_0.5.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2200  test examples: 550
Epoch 0: 55 / 550
Epoch 1: 185 / 550
Epoch 2: 55 / 550
Epoch 9: 55 / 550
Epoch 10: 257 / 550
Epoch 11: 257 / 550
Epoch 12: 252 / 550
Epoch 17: 226 / 550
Epoch 18: 55 / 550
Epoch 19: 226 / 550
Result after 20 epoches: 226 / 550  (41%)

===== svm_traindata.txt.1a.Z_1.5_1.5.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2196  test examples: 549
Epoch 0: 262 / 549
Epoch 1: 61 / 549
Epoch 2: 258 / 549
Epoch 9: 60 / 549
Epoch 10: 258 / 549
Epoch 11: 60 / 549
Epoch 12: 61 / 549
Epoch 17: 106 / 549
Epoch 18: 251 / 549
Epoch 19: 258 / 549
Result after 20 epoches: 258 / 549  (46%)

===== svm_traindata.txt.1a.Z_1.5_1.5.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2196  test examples: 549
Epoch 0: 113 / 549
Epoch 1: 258 / 549
Epoch 2: 258 / 549
Epoch 9: 258 / 549
Epoch 10: 258 / 549
Epoch 11: 258 / 549
Epoch 12: 258 / 549
Epoch 17: 258 / 549
Epoch 18: 258 / 549
Epoch 19: 258 / 549
Result after 20 epoches: 258 / 549  (46%)

===== svm_traindata.txt.1a.Z_1.5_1.5.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2196  test examples: 549
Epoch 0: 173 / 549
Epoch 1: 156 / 549
Epoch 2: 258 / 549
Epoch 9: 143 / 549
Epoch 10: 134 / 549
Epoch 11: 131 / 549
Epoch 12: 151 / 549
Epoch 17: 258 / 549
Epoch 18: 258 / 549
Epoch 19: 152 / 549
Result after 20 epoches: 152 / 549  (27%)

===== svm_traindata.txt.1a.Z_1.5_1.5.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2196  test examples: 549
Epoch 0: 165 / 549
Epoch 1: 183 / 549
Epoch 2: 258 / 549
Epoch 9: 165 / 549
Epoch 10: 258 / 549
Epoch 11: 170 / 549
Epoch 12: 168 / 549
Epoch 17: 173 / 549
Epoch 18: 157 / 549
Epoch 19: 157 / 549
Result after 20 epoches: 157 / 549  (28%)

===== svm_traindata.txt.1a.Z_1.5_1.5.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2196  test examples: 549
Epoch 0: 258 / 549
Epoch 1: 54 / 549
Epoch 2: 184 / 549
Epoch 9: 241 / 549
Epoch 10: 200 / 549
Epoch 11: 198 / 549
Epoch 12: 247 / 549
Epoch 17: 188 / 549
Epoch 18: 197 / 549
Epoch 19: 54 / 549
Result after 20 epoches: 54 / 549  (9%)

===== svm_traindata.txt.1a.Z_1.5_1.5.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2196  test examples: 549
Epoch 0: 54 / 549
Epoch 1: 67 / 549
Epoch 2: 187 / 549
Epoch 9: 193 / 549
Epoch 10: 197 / 549
Epoch 11: 184 / 549
Epoch 12: 199 / 549
Epoch 17: 200 / 549
Epoch 18: 189 / 549
Epoch 19: 253 / 549
Result after 20 epoches: 253 / 549  (46%)

===== svm_traindata.txt.1a.Z_1.5_1.5.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2196  test examples: 549
Epoch 0: 54 / 549
Epoch 1: 258 / 549
Epoch 2: 258 / 549
Epoch 9: 244 / 549
Epoch 10: 258 / 549
Epoch 11: 54 / 549
Epoch 12: 251 / 549
Epoch 17: 235 / 549
Epoch 18: 248 / 549
Epoch 19: 54 / 549
Result after 20 epoches: 54 / 549  (9%)

===== svm_traindata.txt.1a.Z_2.4_2.4.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 9 / 549
Epoch 1: 259 / 549
Epoch 2: 61 / 549
Epoch 9: 259 / 549
Epoch 10: 259 / 549
Epoch 11: 61 / 549
Epoch 12: 65 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 61 / 549
Result after 20 epoches: 61 / 549  (11%)

===== svm_traindata.txt.1a.Z_2.4_2.4.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2194  test examples: 549
Epoch 0: 0 / 549
Epoch 1: 0 / 549
Epoch 2: 259 / 549
Epoch 9: 259 / 549
Epoch 10: 259 / 549
Epoch 11: 54 / 549
Epoch 12: 259 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 61 / 549
Result after 20 epoches: 61 / 549  (11%)

===== svm_traindata.txt.1a.Z_2.4_2.4.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 259 / 549
Epoch 1: 144 / 549
Epoch 2: 155 / 549
Epoch 9: 259 / 549
Epoch 10: 259 / 549
Epoch 11: 126 / 549
Epoch 12: 199 / 549
Epoch 17: 145 / 549
Epoch 18: 259 / 549
Epoch 19: 259 / 549
Result after 20 epoches: 259 / 549  (47%)

===== svm_traindata.txt.1a.Z_2.4_2.4.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 259 / 549
Epoch 1: 194 / 549
Epoch 2: 169 / 549
Epoch 9: 259 / 549
Epoch 10: 182 / 549
Epoch 11: 259 / 549
Epoch 12: 259 / 549
Epoch 17: 176 / 549
Epoch 18: 150 / 549
Epoch 19: 259 / 549
Result after 20 epoches: 259 / 549  (47%)

===== svm_traindata.txt.1a.Z_2.4_2.4.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 259 / 549
Epoch 1: 164 / 549
Epoch 2: 237 / 549
Epoch 9: 54 / 549
Epoch 10: 241 / 549
Epoch 11: 236 / 549
Epoch 12: 69 / 549
Epoch 17: 155 / 549
Epoch 18: 234 / 549
Epoch 19: 236 / 549
Result after 20 epoches: 236 / 549  (42%)

===== svm_traindata.txt.1a.Z_2.4_2.4.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2194  test examples: 549
Epoch 0: 252 / 549
Epoch 1: 259 / 549
Epoch 2: 259 / 549
Epoch 9: 186 / 549
Epoch 10: 122 / 549
Epoch 11: 232 / 549
Epoch 12: 216 / 549
Epoch 17: 207 / 549
Epoch 18: 176 / 549
Epoch 19: 162 / 549
Result after 20 epoches: 162 / 549  (29%)

===== svm_traindata.txt.1a.Z_2.4_2.4.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 259 / 549
Epoch 1: 259 / 549
Epoch 2: 259 / 549
Epoch 9: 259 / 549
Epoch 10: 259 / 549
Epoch 11: 259 / 549
Epoch 12: 259 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 259 / 549
Result after 20 epoches: 259 / 549  (47%)

===== svm_traindata.txt.1a.Z_3.4_3.4.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 70 / 549
Epoch 1: 259 / 549
Epoch 2: 259 / 549
Epoch 9: 57 / 549
Epoch 10: 28 / 549
Epoch 11: 259 / 549
Epoch 12: 59 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 259 / 549
Result after 20 epoches: 259 / 549  (47%)

===== svm_traindata.txt.1a.Z_3.4_3.4.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2194  test examples: 549
Epoch 0: 0 / 549
Epoch 1: 259 / 549
Epoch 2: 259 / 549
Epoch 9: 259 / 549
Epoch 10: 259 / 549
Epoch 11: 259 / 549
Epoch 12: 259 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 54 / 549
Result after 20 epoches: 54 / 549  (9%)

===== svm_traindata.txt.1a.Z_3.4_3.4.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 168 / 549
Epoch 1: 178 / 549
Epoch 2: 259 / 549
Epoch 9: 179 / 549
Epoch 10: 167 / 549
Epoch 11: 259 / 549
Epoch 12: 259 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 134 / 549
Result after 20 epoches: 134 / 549  (24%)

===== svm_traindata.txt.1a.Z_3.4_3.4.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 170 / 549
Epoch 1: 259 / 549
Epoch 2: 174 / 549
Epoch 9: 259 / 549
Epoch 10: 182 / 549
Epoch 11: 259 / 549
Epoch 12: 166 / 549
Epoch 17: 254 / 549
Epoch 18: 170 / 549
Epoch 19: 259 / 549
Result after 20 epoches: 259 / 549  (47%)

===== svm_traindata.txt.1a.Z_3.4_3.4.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 259 / 549
Epoch 1: 64 / 549
Epoch 2: 234 / 549
Epoch 9: 196 / 549
Epoch 10: 228 / 549
Epoch 11: 194 / 549
Epoch 12: 212 / 549
Epoch 17: 149 / 549
Epoch 18: 204 / 549
Epoch 19: 259 / 549
Result after 20 epoches: 259 / 549  (47%)

===== svm_traindata.txt.1a.Z_3.4_3.4.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2194  test examples: 549
Epoch 0: 179 / 549
Epoch 1: 210 / 549
Epoch 2: 207 / 549
Epoch 9: 209 / 549
Epoch 10: 200 / 549
Epoch 11: 180 / 549
Epoch 12: 185 / 549
Epoch 17: 259 / 549
Epoch 18: 182 / 549
Epoch 19: 259 / 549
Result after 20 epoches: 259 / 549  (47%)

===== svm_traindata.txt.1a.Z_3.4_3.4.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2194  test examples: 549
Epoch 0: 0 / 549
Epoch 1: 54 / 549
Epoch 2: 54 / 549
Epoch 9: 259 / 549
Epoch 10: 259 / 549
Epoch 11: 259 / 549
Epoch 12: 258 / 549
Epoch 17: 259 / 549
Epoch 18: 258 / 549
Epoch 19: 54 / 549
Result after 20 epoches: 54 / 549  (9%)

===== svm_traindata.txt.1a.Z_4.3_4.3.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2193  test examples: 549
Epoch 0: 259 / 549
Epoch 1: 259 / 549
Epoch 2: 55 / 549
Epoch 9: 65 / 549
Epoch 10: 55 / 549
Epoch 11: 56 / 549
Epoch 12: 259 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 55 / 549
Result after 20 epoches: 55 / 549  (10%)

===== svm_traindata.txt.1a.Z_4.3_4.3.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2193  test examples: 549
Epoch 0: 0 / 549
Epoch 1: 259 / 549
Epoch 2: 54 / 549
Epoch 9: 259 / 549
Epoch 10: 259 / 549
Epoch 11: 156 / 549
Epoch 12: 259 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 259 / 549
Result after 20 epoches: 259 / 549  (47%)

===== svm_traindata.txt.1a.Z_4.3_4.3.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2193  test examples: 549
Epoch 0: 141 / 549
Epoch 1: 153 / 549
Epoch 2: 259 / 549
Epoch 9: 141 / 549
Epoch 10: 152 / 549
Epoch 11: 259 / 549
Epoch 12: 214 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 259 / 549
Result after 20 epoches: 259 / 549  (47%)

===== svm_traindata.txt.1a.Z_4.3_4.3.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2193  test examples: 549
Epoch 0: 259 / 549
Epoch 1: 107 / 549
Epoch 2: 259 / 549
Epoch 9: 169 / 549
Epoch 10: 169 / 549
Epoch 11: 169 / 549
Epoch 12: 259 / 549
Epoch 17: 169 / 549
Epoch 18: 259 / 549
Epoch 19: 169 / 549
Result after 20 epoches: 169 / 549  (30%)

===== svm_traindata.txt.1a.Z_4.3_4.3.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2193  test examples: 549
Epoch 0: 259 / 549
Epoch 1: 187 / 549
Epoch 2: 54 / 549
Epoch 9: 54 / 549
Epoch 10: 234 / 549
Epoch 11: 259 / 549
Epoch 12: 96 / 549
Epoch 17: 259 / 549
Epoch 18: 259 / 549
Epoch 19: 224 / 549
Result after 20 epoches: 224 / 549  (40%)

===== svm_traindata.txt.1a.Z_4.3_4.3.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2193  test examples: 549
Epoch 0: 54 / 549
Epoch 1: 54 / 549
Epoch 2: 112 / 549
Epoch 9: 251 / 549
Epoch 10: 258 / 549
Epoch 11: 251 / 549
Epoch 12: 69 / 549
Epoch 17: 259 / 549
Epoch 18: 198 / 549
Epoch 19: 168 / 549
Result after 20 epoches: 168 / 549  (30%)

===== svm_traindata.txt.1a.Z_4.3_4.3.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2193  test examples: 549
Epoch 0: 24 / 549
Epoch 1: 24 / 549
Epoch 2: 24 / 549
Epoch 9: 54 / 549
Epoch 10: 258 / 549
Epoch 11: 258 / 549
Epoch 12: 54 / 549
Epoch 17: 258 / 549
Epoch 18: 258 / 549
Epoch 19: 54 / 549
Result after 20 epoches: 54 / 549  (9%)

===== svm_traindata.txt.1a.Z_6.0_6.0.max =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2189  test examples: 548
Epoch 0: 0 / 548
Epoch 1: 0 / 548
Epoch 2: 0 / 548
Epoch 9: 258 / 548
Epoch 10: 258 / 548
Epoch 11: 258 / 548
Epoch 12: 258 / 548
Epoch 17: 68 / 548
Epoch 18: 68 / 548
Epoch 19: 258 / 548
Result after 20 epoches: 258 / 548  (47%)

===== svm_traindata.txt.1a.Z_6.0_6.0.max5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2189  test examples: 548
Epoch 0: 0 / 548
Epoch 1: 0 / 548
Epoch 2: 0 / 548
Epoch 9: 258 / 548
Epoch 10: 151 / 548
Epoch 11: 151 / 548
Epoch 12: 158 / 548
Epoch 17: 258 / 548
Epoch 18: 153 / 548
Epoch 19: 258 / 548
Result after 20 epoches: 258 / 548  (47%)

===== svm_traindata.txt.1a.Z_6.0_6.0.mean =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2189  test examples: 548
Epoch 0: 159 / 548
Epoch 1: 258 / 548
Epoch 2: 144 / 548
Epoch 9: 258 / 548
Epoch 10: 168 / 548
Epoch 11: 258 / 548
Epoch 12: 174 / 548
Epoch 17: 258 / 548
Epoch 18: 166 / 548
Epoch 19: 215 / 548
Result after 20 epoches: 215 / 548  (39%)

===== svm_traindata.txt.1a.Z_6.0_6.0.mid =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2189  test examples: 548
Epoch 0: 186 / 548
Epoch 1: 185 / 548
Epoch 2: 258 / 548
Epoch 9: 184 / 548
Epoch 10: 258 / 548
Epoch 11: 151 / 548
Epoch 12: 258 / 548
Epoch 17: 186 / 548
Epoch 18: 93 / 548
Epoch 19: 186 / 548
Result after 20 epoches: 186 / 548  (33%)

===== svm_traindata.txt.1a.Z_6.0_6.0.min =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2189  test examples: 548
Epoch 0: 218 / 548
Epoch 1: 56 / 548
Epoch 2: 251 / 548
Epoch 9: 258 / 548
Epoch 10: 245 / 548
Epoch 11: 218 / 548
Epoch 12: 217 / 548
Epoch 17: 131 / 548
Epoch 18: 184 / 548
Epoch 19: 218 / 548
Result after 20 epoches: 218 / 548  (39%)

===== svm_traindata.txt.1a.Z_6.0_6.0.min5 =====
dimension(Number of neurons for input layer) : 5
number of training examples: 2189  test examples: 548
Epoch 0: 54 / 548
Epoch 1: 206 / 548
Epoch 2: 255 / 548
Epoch 9: 208 / 548
Epoch 10: 211 / 548
Epoch 11: 252 / 548
Epoch 12: 255 / 548
Epoch 17: 258 / 548
Epoch 18: 199 / 548
Epoch 19: 257 / 548
Result after 20 epoches: 257 / 548  (46%)

===== svm_traindata.txt.1a.Z_6.0_6.0.sd =====
dimension(Number of neurons for input layer) : 1
number of training examples: 2189  test examples: 548
Epoch 0: 0 / 548
Epoch 1: 0 / 548
Epoch 2: 0 / 548
Epoch 9: 248 / 548
Epoch 10: 54 / 548
Epoch 11: 258 / 548
Epoch 12: 258 / 548
Epoch 17: 178 / 548
Epoch 18: 177 / 548
Epoch 19: 54 / 548
Result after 20 epoches: 54 / 548  (9%)

